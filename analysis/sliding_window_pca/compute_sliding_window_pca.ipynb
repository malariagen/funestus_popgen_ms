{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73845a85-f32a-476a-b080-13b3f8267fc8",
   "metadata": {},
   "source": [
    "# Sliding window PCA on malaria gen data\n",
    "\n",
    "This notebook computes sliding window PCAs for data accessible through the `malariagen_data` package. After running this notebook, you can visualise the results with the `plot_sliding_window_pca.ipynb` notebook. The computations take a while (approx. 25 minutes for chrom 3RL (84Mb) on 620 samples using dask cluster with 50 nodes with default parameters for variant selection) so it is advisable to run it on a cluster (here we use dask). The output is approx. 4 Mb for PC1 and 2 on chrom 3RL for 620 samples.\n",
    "\n",
    "You need to create an account to access the data, more info here: https://malariagen.github.io/vector-data/vobs/vobs-data-access.html  \n",
    "Then you need to sign in once per session, by running `gcloud auth application-default login` in the same environment used to run this notebook and following the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe2dd6-01d0-4a88-aa86-7d78e4078aef",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504d8fc1-604b-441d-91f7-675f60c2500b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import malariagen_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import allel\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False}) # Silence large chunk warnings\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "from dask_gateway import Gateway\n",
    "import numba\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Sending large graph of size\") #Silence large graph warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0a63a-5c1d-4e71-8346-f90cbd9d5ce2",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "NOTE: the following changes have to be made to run this on Ag instead of Af. \n",
    "- Change `Af1` to `Ag3` in the access data function\n",
    "- Remove the `site_filter_analysis` argument to use the default for Ag3\n",
    "- Remove the steps used to add extra metadata\n",
    "- Change `variant_filter_pass_funestus` in the helper function `prepare_genotypes_positions` to the desired filter (e.g. `variant_filter_pass_gamb_colu_arab` for all three vector species in the complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b68f1b-51ba-414e-82f0-c33f7c45000c",
   "metadata": {},
   "source": [
    "Additionally specify which samples you want to use, based on the metadata, see below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1f413-633a-4909-901c-7fb6bf842c15",
   "metadata": {},
   "source": [
    "### Access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b801fb5f-e160-48b3-b3cb-e9f66c2a059e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <table class=\"malariagen-af1\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\" colspan=\"2\">MalariaGEN Af1 API client</th>\n",
       "                    </tr>\n",
       "                    <tr><td colspan=\"2\" style=\"text-align: left\">\n",
       "                        Please note that data are subject to terms of use,\n",
       "                        for more information see <a href=\"https://www.malariagen.net/data\">\n",
       "                        the MalariaGEN website</a> or contact support@malariagen.net.\n",
       "                        See also the <a href=\"https://malariagen.github.io/malariagen-data-python/v10.0.0/Af1.html\">Af1 API docs</a>.\n",
       "                    </td></tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Storage URL\n",
       "                        </th>\n",
       "                        <td>gs://vo_afun_release_master_us_central1</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Data releases available\n",
       "                        </th>\n",
       "                        <td>1.0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Results cache\n",
       "                        </th>\n",
       "                        <td>None</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Cohorts analysis\n",
       "                        </th>\n",
       "                        <td>20240515</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Site filters analysis\n",
       "                        </th>\n",
       "                        <td>sc_20220908</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Software version\n",
       "                        </th>\n",
       "                        <td>malariagen_data 10.0.0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Client location\n",
       "                        </th>\n",
       "                        <td>Iowa, United States (Google Cloud us-central1)</td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        "
      ],
      "text/plain": [
       "<MalariaGEN Af1 API client>\n",
       "Storage URL             : gs://vo_afun_release_master_us_central1\n",
       "Data releases available : 1.0\n",
       "Results cache           : None\n",
       "Cohorts analysis        : 20240515\n",
       "Site filters analysis   : sc_20220908\n",
       "Software version        : malariagen_data 10.0.0\n",
       "Client location         : Iowa, United States (Google Cloud us-central1)\n",
       "---\n",
       "Please note that data are subject to terms of use,\n",
       "for more information see https://www.malariagen.net/data\n",
       "or contact support@malariagen.net. For API documentation see \n",
       "https://malariagen.github.io/malariagen-data-python/v10.0.0/Af1.html"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we read in data for funestus using the static cutoff site filter\n",
    "af1 = malariagen_data.Af1(site_filters_analysis=\"sc_20220908\")\n",
    "af1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3edd3af-211c-4c9d-a389-46306c917e46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>partner_sample_id</th>\n",
       "      <th>contributor</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sex_call</th>\n",
       "      <th>...</th>\n",
       "      <th>karyotype_3La</th>\n",
       "      <th>karyotype_3Ra</th>\n",
       "      <th>karyotype_3Rb</th>\n",
       "      <th>karyotype_2Ra</th>\n",
       "      <th>karyotype_2Rh</th>\n",
       "      <th>karyotype_2Rt</th>\n",
       "      <th>mitochondrial_id</th>\n",
       "      <th>subset_1</th>\n",
       "      <th>subset_2</th>\n",
       "      <th>subset_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VBS24195</td>\n",
       "      <td>1229-GH-A-GH01</td>\n",
       "      <td>Samuel Dadzie</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Dimabi</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>9.420</td>\n",
       "      <td>-1.083</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3R+/a</td>\n",
       "      <td>3Rb/b</td>\n",
       "      <td>2Ra/a</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>funestus-lineageI-clusterB</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBS24196</td>\n",
       "      <td>1229-GH-A-GH02</td>\n",
       "      <td>Samuel Dadzie</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Gbullung</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>9.488</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Ra/a</td>\n",
       "      <td>3Rb/b</td>\n",
       "      <td>2Ra/a</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>funestus-lineageI-clusterB</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBS24197</td>\n",
       "      <td>1229-GH-A-GH03</td>\n",
       "      <td>Samuel Dadzie</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Dimabi</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>9.420</td>\n",
       "      <td>-1.083</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3R+/a</td>\n",
       "      <td>3Rb/b</td>\n",
       "      <td>2Ra/a</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>funestus-lineageI-clusterB</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VBS24198</td>\n",
       "      <td>1229-GH-A-GH04</td>\n",
       "      <td>Samuel Dadzie</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Dimabi</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>9.420</td>\n",
       "      <td>-1.083</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3R+/a</td>\n",
       "      <td>3Rb/b</td>\n",
       "      <td>2Ra/a</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>funestus-lineageI-clusterB</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VBS24199</td>\n",
       "      <td>1229-GH-A-GH05</td>\n",
       "      <td>Samuel Dadzie</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Gupanarigu</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>9.497</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Ra/a</td>\n",
       "      <td>3Rb/b</td>\n",
       "      <td>2Ra/a</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>2R+/+</td>\n",
       "      <td>funestus-lineageI-clusterB</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id partner_sample_id    contributor country    location  year  month  \\\n",
       "0  VBS24195    1229-GH-A-GH01  Samuel Dadzie   Ghana      Dimabi  2017      8   \n",
       "1  VBS24196    1229-GH-A-GH02  Samuel Dadzie   Ghana    Gbullung  2017      7   \n",
       "2  VBS24197    1229-GH-A-GH03  Samuel Dadzie   Ghana      Dimabi  2017      7   \n",
       "3  VBS24198    1229-GH-A-GH04  Samuel Dadzie   Ghana      Dimabi  2017      8   \n",
       "4  VBS24199    1229-GH-A-GH05  Samuel Dadzie   Ghana  Gupanarigu  2017      8   \n",
       "\n",
       "   latitude  longitude sex_call  ... karyotype_3La karyotype_3Ra  \\\n",
       "0     9.420     -1.083        F  ...           NaN         3R+/a   \n",
       "1     9.488     -1.009        F  ...           NaN         3Ra/a   \n",
       "2     9.420     -1.083        F  ...           NaN         3R+/a   \n",
       "3     9.420     -1.083        F  ...           NaN         3R+/a   \n",
       "4     9.497     -0.952        F  ...           NaN         3Ra/a   \n",
       "\n",
       "   karyotype_3Rb karyotype_2Ra karyotype_2Rh karyotype_2Rt  \\\n",
       "0          3Rb/b         2Ra/a         2R+/+         2R+/+   \n",
       "1          3Rb/b         2Ra/a         2R+/+         2R+/+   \n",
       "2          3Rb/b         2Ra/a         2R+/+         2R+/+   \n",
       "3          3Rb/b         2Ra/a         2R+/+         2R+/+   \n",
       "4          3Rb/b         2Ra/a         2R+/+         2R+/+   \n",
       "\n",
       "             mitochondrial_id subset_1 subset_2 subset_3  \n",
       "0  funestus-lineageI-clusterB        Y        Y        Y  \n",
       "1  funestus-lineageI-clusterB        Y        Y        Y  \n",
       "2  funestus-lineageI-clusterB        Y        Y        Y  \n",
       "3  funestus-lineageI-clusterB        Y        Y        Y  \n",
       "4  funestus-lineageI-clusterB        Y        Y        Y  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we read in the sample metadata for Af1.0 and\n",
    "#we add some of the metadata contained in supplementary table 1 tab 2\n",
    "extra_meta = pd.read_csv(\"../../metadata/supp1_tab2.csv\")\n",
    "extra_meta.rename(columns={'VBS_sample_id': 'sample_id'}, inplace=True)\n",
    "#subset to useful columns and prevent duplicates\n",
    "extra_meta = extra_meta[['sample_id',\n",
    "       'geographic_cohort', 'geographic_cohort_colour', 'geographic_cohort_code'\n",
    "       'geographic_cohort_shape', 'PCA_cohort', 'PCA_cohort_colour',\n",
    "       'karyotype_3La', 'karyotype_3Ra', 'karyotype_3Rb', 'karyotype_2Ra',\n",
    "       'karyotype_2Rh', 'karyotype_2Rt', 'mitochondrial_id', 'subset_1',\n",
    "       'subset_2', 'subset_3']]\n",
    "af1.add_extra_metadata(extra_meta)\n",
    "meta = af1.sample_metadata(sample_sets='1.0')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99399718-09ee-427d-bfc3-6fb0c452dc21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run on all samples except the Ghana_Northern-Region geographic cohort\n",
    "sample_idx = meta.loc[meta.geographic_cohort!='Ghana_Northern-Region'].index\n",
    "len(sample_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda8658-670c-4f48-add8-cf28fed9444f",
   "metadata": {},
   "source": [
    "### Set up dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a335dc-b944-4c74-be31-d5ff59d83c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceee67a45c7438f85389243df3b6a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "conda_prefix = os.environ[\"CONDA_PREFIX\"]\n",
    "current_environment = 'global/'+conda_prefix.split('/')[5]\n",
    "cluster = gateway.new_cluster(\n",
    "    profile='standard', \n",
    "    conda_environment = current_environment,\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1741117-7349-481d-8586-144abab60721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client=cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2717c204-f28e-4c4c-bcdd-ef6cd3288492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d90b0-08c9-4a4a-be8f-d9f4915893bd",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ed94fb-3df8-46ef-b3ee-a5effe319382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_genotypes_positions(chrom, posl, posu, release, sample_idx):\n",
    "    #access snp_calls xarray dataset\n",
    "    snp_calls = af1.snp_calls(region=f'{chrom}:{posl}-{posu}', sample_sets=release)\n",
    "    variant_filter = snp_calls.variant_filter_pass_funestus.compute()\n",
    "    #apply site filter to genotypes\n",
    "    gt = snp_calls.call_genotype[variant_filter,:,:]\n",
    "    #select the desired samples\n",
    "    gt = gt[:,sample_idx,:]\n",
    "    #broadcast gt as genotype dask array\n",
    "    gt = allel.GenotypeDaskArray(gt.data)\n",
    "    #apply site filter to positions\n",
    "    pos = snp_calls.variant_position[variant_filter]\n",
    "    #broadcast positions as array\n",
    "    pos = pos.data\n",
    "    return(gt, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d200791-fc77-4785-a6ad-f9788d6ef3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to count the presence of each allele in a given array of genotypes (samples * variants * alleles)\n",
    "# and return an array of allele counts with a row for each possible allele (limited by max_allele) for each sample, and column for each variant\n",
    "@numba.njit(\n",
    "    numba.int8[:, :](numba.int8[:, :, :], numba.int8), nogil=True)\n",
    "def numpy_genotype_tensor_to_allele_counts_melt(gt, max_allele):\n",
    "    # Create an array of zeros (for defaults) with the same number of colums (variants) as the genotype array but a row for each allele, for each sample\n",
    "    out = np.zeros((gt.shape[0] * (max_allele + 1), gt.shape[1]), dtype=np.int8)\n",
    "    # For each row (sample) in the genotype array\n",
    "    for i in range(gt.shape[0]):\n",
    "        # For each column (variant) in the genotype array\n",
    "        for j in range(gt.shape[1]):\n",
    "            # For each allele in the genotype array \n",
    "            for k in range(gt.shape[2]):\n",
    "                allele = gt[i, j, k]\n",
    "                # If the value in the genotype array at this row and colum and 3rd dimension (i.e. the allele value) is between 0 and max_allele  \n",
    "                if 0 <= allele <= max_allele:\n",
    "                    # Increment the value of the `out` array at the row corresponding to this allele for this sample, at the corresponding variant column\n",
    "                    out[(i * (max_allele + 1)) + allele, j] += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e32ed0c-eeed-4257-8459-f927188db255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to do the same thing as the previous function\n",
    "# but the Dask way\n",
    "def dask_genotype_tensor_to_allele_counts_melt(gt, max_allele):\n",
    "\n",
    "    # Determine output chunks - change axis 0; preserve axis 1; drop axis 2.\n",
    "    dim0_chunks = tuple(np.array(gt.chunks[0]) * (max_allele + 1))\n",
    "    chunks = (dim0_chunks, gt.chunks[1])\n",
    "\n",
    "    return gt.map_blocks(\n",
    "        numpy_genotype_tensor_to_allele_counts_melt,\n",
    "        max_allele=max_allele,\n",
    "        chunks=chunks,\n",
    "        dtype=\"i1\",\n",
    "        drop_axis=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17503e01-db77-47cb-828f-e7778db18788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_variants(gt, pos, n_samples, maf, missing_frac, variant_density, \n",
    "                    af_tolerance, frac_acc, seed = 42):\n",
    "    \n",
    "    #count alleles \n",
    "    ac = gt.count_alleles(max_allele=3)\n",
    "    #compute frequencies\n",
    "    af = ac.to_frequencies()\n",
    "    \n",
    "    print(f\"Read in {gt.shape[0]} accessible sites\")\n",
    "    \n",
    "    #filters for missingness, near-biallelism and maf\n",
    "    missing_filter = ac.sum(axis=1) >= (1-missing_frac)*2*n_samples\n",
    "    #Find nearly biallelic sites: \n",
    "    #Require two alleles with frequencies ≥ maf and\n",
    "    #tolerate more than two alleles if the others are below the af_tolerance\n",
    "    maf_filter = ((af >= maf).sum(axis=1) == 2) & ((af <= af_tolerance).sum(axis=1) == 2)\n",
    "    \n",
    "    #If many variants, downsample to the desired number\n",
    "    #Variant density is given in the number of desired variants Mb \n",
    "    #(taking into account the mean accessibility rate)\n",
    "    combined_filter = ((missing_filter) & (maf_filter)).compute()\n",
    "    n_candidates = combined_filter.sum()\n",
    "    print(f\"Contains {n_candidates} candiate variant sites\")\n",
    "    n_variants = int(variant_density * gt.shape[0] / frac_acc / 1_000_000)\n",
    "    print(f\"We want {n_variants} sites for sliding window PCA\")\n",
    "    if n_candidates > n_variants:\n",
    "        candidate_idx = np.arange(gt.shape[0])[combined_filter]\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "        selection_idx = rng.choice(candidate_idx, n_variants, replace=False)\n",
    "        selection_idx = np.sort(selection_idx)\n",
    "    else:\n",
    "        selection_idx = np.arange(gt.shape[0])[combined_filter]\n",
    "    \n",
    "    #get filtered allele counts\n",
    "    ac_f = ac.take(selection_idx, axis=0)\n",
    "    pos_f = pos[selection_idx]\n",
    "    gt_f = gt.take(selection_idx, axis=0)\n",
    "    \n",
    "    #get major allele index\n",
    "    major_alleles = da.argmax(ac_f, axis=1)\n",
    "    \n",
    "    #melted allele counts\n",
    "    melted_counts = dask_genotype_tensor_to_allele_counts_melt(gt_f, max_allele=3)\n",
    "    variant_counts = da.take(melted_counts, np.arange(major_alleles.shape[0])*4+major_alleles.compute(), axis=0)\n",
    "    variant_pos = pos_f.compute()\n",
    "    \n",
    "    return variant_counts, variant_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f462d21-caef-4e0e-b3f6-b247cede7a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_windows(n_vars, window_size, step_size):\n",
    "    n_windows = (n_vars-window_size+step_size)//step_size\n",
    "    starts = (np.arange(0,n_windows)*step_size).astype(int)\n",
    "    ends = (starts+window_size).astype(int)\n",
    "    return(starts,ends,n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "599b038a-fd60-4434-a784-a09ecb17399d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variant_check(computed_variants):\n",
    "    for i in range(3):\n",
    "        if (computed_variants == i).all(axis=1).any():\n",
    "            loc_invariant = (computed_variants == i).all(axis=1)\n",
    "            computed_variants = computed_variants[~loc_invariant]\n",
    "            print(f'Removed {sum(loc_invariant)} invariant sites')\n",
    "    return(computed_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb1b5aa-a56e-4b4f-8a07-7fa0eece52cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_PCA_in_window(computed_variants, n_pc):\n",
    "    coords, model = allel.pca(computed_variants, n_components=n_pc, scaler='patterson')\n",
    "    explained_variance = model.explained_variance_ratio_\n",
    "    return(coords, explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb794b7b-800f-452d-917c-e135ea7140a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_reading_frame(\n",
    "        chrom, sample_idx, n_pc, posl, posu, release, window_size, step_size, \n",
    "        maf, missing_frac, variant_density, af_tolerance, frac_acc):\n",
    "    \n",
    "    #read in genotypes and positions and subset to desired individuals\n",
    "    gt, pos = prepare_genotypes_positions(\n",
    "        chrom, posl, posu, release, sample_idx)\n",
    "    \n",
    "    #select variants and return counts per individual of variant allele\n",
    "    variant_counts, variant_pos = select_variants(\n",
    "        gt, pos, len(sample_idx), maf, missing_frac, \n",
    "        variant_density, af_tolerance, frac_acc)\n",
    "    \n",
    "    #split data into windows\n",
    "    start_idx, end_idx, n_windows = compute_windows(\n",
    "        len(variant_pos), window_size, step_size)\n",
    "    \n",
    "    #check that size of data is sufficient for at least one window\n",
    "    if n_windows<1:\n",
    "        return np.array([[[]]]), np.array([[]]), np.array([[]]), variant_pos.max()+step_size\n",
    "    \n",
    "    #generate objects to store results \n",
    "    pc_values = np.zeros((n_pc, n_windows, len(sample_idx)))\n",
    "    var_exp = np.zeros((n_pc, n_windows))\n",
    "    pos_win = np.zeros((n_windows, 3))\n",
    "    \n",
    "    #loop through windows to compute PCA\n",
    "    for n, start, end in zip(np.arange(n_windows), start_idx, end_idx):\n",
    "        variants_window = variant_counts[start:end].compute()\n",
    "        variants_window = variant_check(variants_window)\n",
    "        coords, variance = perform_PCA_in_window(variants_window, n_pc)\n",
    "        \n",
    "        for pc in np.arange(n_pc):\n",
    "            #Check if you want to flip the PC axis\n",
    "            if n>0:\n",
    "                no_flip = np.sum(np.abs(pc_values[pc,n-1,:] - coords[:,pc]))\n",
    "                flip = np.sum(np.abs(pc_values[pc,n-1,:] + coords[:,pc]))\n",
    "                if flip < no_flip:\n",
    "                    coords[:,pc] *= -1\n",
    "            #store values for each pc\n",
    "            pc_values[pc,n,:] = coords[:,pc]\n",
    "        #store explained variance\n",
    "        var_exp[:,n] = variance\n",
    "        #store positions\n",
    "        pos_win[n,:] = (variant_pos[start], variant_pos[end-1], variant_pos[start:end].mean())\n",
    "        \n",
    "    print(f'Computed PC in {n_windows} windows, spanning from {variant_pos[start_idx[0]]} to {variant_pos[end-1]}')\n",
    "    return pc_values, var_exp, pos_win, variant_pos[start+step_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94204ec2-3062-4d48-9d09-e16df05f3005",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc72371-1daf-4849-91cc-2a61507d6f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def loop_through_reading_frames(chrom, sample_idx, outdir=None, n_pc=1, name=None, \n",
    "                                posl=-1, posu=-1, release='1.0',\n",
    "                                reading_frame_size=10_000_000,\n",
    "                                window_size = 5000, step_size=1000, maf=0.02, missing_frac=0.10, \n",
    "                                variant_density=5000, af_tolerance=0.001, frac_acc=0.77):\n",
    "    \n",
    "    \"\"\"\n",
    "    Top function to run the sliding window PCA\n",
    "    Saves pc_values, explained_variance and positions as np files in outdir\n",
    "\n",
    "    ARGUMENTS\n",
    "    chrom: chromosome name\n",
    "    sample_idx: sample indices in gt array\n",
    "    outdir: directory where to save the data\n",
    "    n_pc: number of pcs to compute (tested for 1 and 2)\n",
    "    posl: lower genomic coordinate if not using the whole chromosome\n",
    "    posu: upper genomic coordinate if not using the whole chromosome\n",
    "    release: data release(s) to use\n",
    "    reading_frame_size: number of bases to process at a time\n",
    "    window_size: number of variant sites per window\n",
    "    step_size: number of variants by which the window slides\n",
    "    maf: minor allele frequency for selecting variants\n",
    "    variant_density: desired mean number of variants per Mb\n",
    "    af_tolerance: tolerated frequency of alternative minor alleles in selecting variants\n",
    "    frac_acc: fraction of accessible sites (depending on site filter)\n",
    "    \"\"\"\n",
    "    \n",
    "    #If no name provided, use chrom as name\n",
    "    if name is None:\n",
    "        name = chrom\n",
    "    #If no outdir provided, use `output`\n",
    "    if outdir is None:\n",
    "        outdir = 'output'\n",
    "    #set up directory if it does not exist yet\n",
    "    if not os.path.isdir(outdir):\n",
    "        ! mkdir {outdir}\n",
    "    \n",
    "    #process to the end of the specified region or to the end of chromosome if not specified\n",
    "    if posu==-1:\n",
    "        posu = af1.genome_sequence(region=chrom).shape[0]\n",
    "    #start from posl if specified, otherwise from start of chromosome\n",
    "    rf_start = max(posl, 1)\n",
    "    #process to the end of the specified region, or for the lenght of one reading frame\n",
    "    rf_end = min(posu, rf_start+reading_frame_size)\n",
    "    \n",
    "    #compute pcs for the first reading frame\n",
    "    pc_values, var_exp, pos_win, rf_start = process_reading_frame(\n",
    "        chrom, sample_idx, n_pc, rf_start, rf_end, release, \n",
    "        window_size, step_size, maf, missing_frac, variant_density, \n",
    "        af_tolerance, frac_acc)\n",
    "    \n",
    "    #save intermediate results\n",
    "    np.save(f'{outdir}/{name}_pc_values.npy', pc_values)\n",
    "    np.save(f'{outdir}/{name}_var_exp.npy', var_exp)\n",
    "    np.save(f'{outdir}/{name}_positions.npy', pos_win)    \n",
    "    print(f'Processed chromosome {chrom} up to {int(pos_win[-1,1])}')\n",
    "    \n",
    "    #process further reading frames until the end of the region\n",
    "    while rf_end < posu:\n",
    "        rf_end = min(posu, rf_start+reading_frame_size)\n",
    "        pc_values_rf, var_exp_rf, pos_win_rf, rf_start = process_reading_frame(\n",
    "            chrom, sample_idx, n_pc, rf_start, rf_end, release, window_size, \n",
    "            step_size, maf, missing_frac, variant_density, af_tolerance, frac_acc)\n",
    "        \n",
    "        #Check that the latest reading frame is not returned empty\n",
    "        if pc_values_rf.shape[1]>0:\n",
    "            #Check if you want to flip the PC axes\n",
    "            for pc in np.arange(n_pc):\n",
    "                no_flip = np.sum(np.abs(pc_values_rf[pc,0,:] - pc_values[pc,-1,:]))\n",
    "                flip = np.sum(np.abs(pc_values_rf[pc,0,:] + pc_values[pc,-1,:]))\n",
    "                if flip < no_flip:\n",
    "                    pc_values_rf[pc] *= -1\n",
    "            \n",
    "            #append data from latest reading frame\n",
    "            pc_values = np.concatenate((pc_values, pc_values_rf),axis=1)\n",
    "            var_exp = np.concatenate((var_exp, var_exp_rf), axis=1)\n",
    "            pos_win = np.concatenate((pos_win, pos_win_rf))\n",
    "            \n",
    "        #save results\n",
    "        np.save(f'{outdir}/{name}_pc_values.npy', pc_values)\n",
    "        np.save(f'{outdir}/{name}_var_exp.npy', var_exp)\n",
    "        np.save(f'{outdir}/{name}_positions.npy', pos_win)  \n",
    "        print(f'Processed chromosome {chrom} up to {int(pos_win[-1,1])}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66c3ab-3c4c-428e-be46-26d6f9fbda5b",
   "metadata": {},
   "source": [
    "### Run computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebb6e42c-2270-4574-b7cc-464ca5a526a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "chrom='3RL'\n",
    "n_pc=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec9a397f-bd75-4503-b236-b62accdc28eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 8125579 accessible sites\n",
      "Contains 478477 candiate variant sites\n",
      "We want 52763 sites for sliding window PCA\n",
      "Computed PC in 48 windows, spanning from 210065 to 9891797\n",
      "Processed chromosome 3RL up to 9891797\n",
      "Read in 8341156 accessible sites \n",
      "Contains 516570 candiate variant sites\n",
      "We want 54163 sites for sliding window PCA\n",
      "Computed PC in 50 windows, spanning from 9206548 to 19177477\n",
      "Processed chromosome 3RL up to 19177477\n",
      "Read in 7910978 accessible sites \n",
      "Contains 490313 candiate variant sites\n",
      "We want 51369 sites for sliding window PCA\n",
      "Computed PC in 47 windows, spanning from 18432665 to 28331822\n",
      "Processed chromosome 3RL up to 28331822\n",
      "Read in 8218631 accessible sites \n",
      "Contains 503788 candiate variant sites\n",
      "We want 53367 sites for sliding window PCA\n",
      "Computed PC in 49 windows, spanning from 27605384 to 37533738\n",
      "Processed chromosome 3RL up to 37533738\n",
      "Read in 7678500 accessible sites \n",
      "Contains 363082 candiate variant sites\n",
      "We want 49860 sites for sliding window PCA\n",
      "Computed PC in 45 windows, spanning from 36625395 to 46407797\n",
      "Processed chromosome 3RL up to 46407797\n",
      "Read in 5413418 accessible sites \n",
      "Contains 308196 candiate variant sites\n",
      "We want 35152 sites for sliding window PCA\n",
      "Computed PC in 31 windows, spanning from 45594318 to 55565338\n",
      "Processed chromosome 3RL up to 55565338\n",
      "Read in 7736385 accessible sites \n",
      "Contains 505086 candiate variant sites\n",
      "We want 50236 sites for sliding window PCA\n",
      "Computed PC in 46 windows, spanning from 54805894 to 64737272\n",
      "Processed chromosome 3RL up to 64737272\n",
      "Read in 7375691 accessible sites \n",
      "Contains 481271 candiate variant sites\n",
      "We want 47894 sites for sliding window PCA\n",
      "Computed PC in 43 windows, spanning from 63927479 to 73720378\n",
      "Processed chromosome 3RL up to 73720378\n",
      "Read in 8065419 accessible sites \n",
      "Contains 498974 candiate variant sites\n",
      "We want 52372 sites for sliding window PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 10:20:35,575 - distributed.client - WARNING - Couldn't gather 1 keys, rescheduling (('getitem-b17d9653c4e5f435615d135b11c361da', 4, 3),)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed PC in 48 windows, spanning from 72837372 to 82780763\n",
      "Processed chromosome 3RL up to 82780763\n",
      "Read in 2346367 accessible sites \n",
      "Contains 105883 candiate variant sites\n",
      "We want 15236 sites for sliding window PCA\n",
      "Computed PC in 11 windows, spanning from 81993621 to 84433783\n",
      "Processed chromosome 3RL up to 84433783\n"
     ]
    }
   ],
   "source": [
    "loop_through_reading_frames(chrom=chrom, sample_idx=sample_idx, n_pc=n_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d7410-fc9c-4874-b300-48bf7099189d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe82d9-660c-4d19-89e3-5d36358bb4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48437f5-99d1-4ab1-a11f-9f7c10e8464e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "588189ca-cec7-4a7e-b188-ea1d9a0a53ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03f261-5b8a-40be-8179-b7a9265a09e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-mgenv-6.0.6",
   "language": "python",
   "name": "conda-env-global-global-mgenv-6.0.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
