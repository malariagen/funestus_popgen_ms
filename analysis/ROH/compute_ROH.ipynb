{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dc3bce-a070-4b49-aa68-2055130fac61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import zarr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import allel\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False}) # Silence large chunk warnings\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "from dask_gateway import Gateway\n",
    "import functools\n",
    "import numcodecs\n",
    "from fsspec.implementations.zip import ZipFileSystem\n",
    "from collections.abc import Mapping\n",
    "import gcsfs\n",
    "import numba\n",
    "import psutil\n",
    "from humanize import naturalsize\n",
    "\n",
    "\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from pyprojroot import here\n",
    "from bokeh.plotting import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c4002-e653-40b0-b87b-fe5f851b88fe",
   "metadata": {},
   "source": [
    "### Connect to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ccfb58-324b-4a05-bdb0-a07c9ab25771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/global/16bb9cfbdc4544739e848604ee66ec4039fbdb901ef288a6c32f7f07c423040b-20241122-101919-730858-80-mgenv-6.0.6/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "gcs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d6f9b7-940f-4b3b-80d2-86e1c3619bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vo_afun_release_master_us_central1/reference',\n",
       " 'vo_afun_release_master_us_central1/v1.0',\n",
       " 'vo_afun_release_master_us_central1/v1.0-config.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs.ls('vo_afun_release_master_us_central1')[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e69d8-6d85-4166-bcf8-84cacbff565d",
   "metadata": {},
   "source": [
    "### Set up data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1690c239-fb44-4b08-b483-61f301ff7097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "production_root = Path('vo_afun_release_master_us_central1')\n",
    "vo_afun_staging = Path(production_root, 'v1.0')\n",
    "sampleset_staging_dir = Path(vo_afun_staging, 'snp_genotypes', 'all')\n",
    "\n",
    "#Decision tree or static filters\n",
    "genomic_positions_site_filter_dt_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/dt_20200416/funestus'\n",
    "genomic_positions_site_filter_sc_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/sc_20220908/funestus'\n",
    "\n",
    "repo_clone_path = here()\n",
    "config_path = repo_clone_path / 'analysis' / 'config.yml'\n",
    "\n",
    "with open(config_path) as fh:\n",
    "    config = yaml.load(fh, Loader=yaml.BaseLoader)\n",
    "    \n",
    "samplesets = config[\"sample_sets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf71dd-426e-49d1-bf7a-4c889d51ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../../metadata/supp1_tab2.csv\")\n",
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b3bd4-05bc-4ed0-bec3-7d2975d106ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0b26291-ac25-4aa7-9741-71e4199d5494",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connect to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679b86f-e4be-41b6-b2fd-ce376b66d0ec",
   "metadata": {},
   "source": [
    "### Set up dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b492e3f2-f9d9-493e-b282-660aec316ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b2d617f-74f2-477a-8b7b-ba3751b9e194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666564b3ccff4860b0b11ac485cb60b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gateway = Gateway()\n",
    "conda_prefix = os.environ[\"CONDA_PREFIX\"]\n",
    "current_environment = 'global/'+conda_prefix.split('/')[5]\n",
    "cluster = gateway.new_cluster(\n",
    "    profile='standard', \n",
    "    conda_environment = current_environment,\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46dfbc3d-d1cb-417e-9310-d288e5fdb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0037e32b-53c4-441c-9b8d-d55de678aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f186b-b990-4a68-92ed-686cd533698d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25f5378-1ce4-4b1e-a5f7-6c0761ede62e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5cf60b-00d0-471c-b4d3-e4b84280a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single array from field/chrom/sampleset\n",
    "# internal path for calldata is chrom/calldata/field\n",
    "# sampleset_calldata = sampleset_staging_dir / sset\n",
    "# sampleset is needed to load species spec.\n",
    "def load_single_field(zarr_path, internal_path, sset, exclude_males=False, samples=None):\n",
    "      \n",
    "    inz = zarr.group(is_gcloud(zarr_path), overwrite=False)\n",
    "    \n",
    "    oo = da.from_zarr(inz[internal_path])  \n",
    "    \n",
    "    if oo.ndim == 1:\n",
    "        oo = oo.reshape((1, -1))\n",
    "           \n",
    "    return oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9e3c16-436c-4489-be5b-3b9009c5d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General function to concatenate data.\n",
    "## Selected chunk size may be more appropriate for some than others.\n",
    "def concatenate_along_axis(base_dir, internal_path, req_samplesets):\n",
    "    \n",
    "    # work out shape\n",
    "    data = [load_single_field(base_dir / ss, internal_path, ss) for ss in req_samplesets]\n",
    "    \n",
    "    return da.concatenate(data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e3ca69-7759-4eb9-9190-9d0de2d65802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gcloud(path):\n",
    "    \n",
    "    try: \n",
    "        return gcs.get_mapper(path.as_posix())\n",
    "    except NameError as e:\n",
    "        return path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048c177f-8fab-462d-a8d0-48e469c1f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_filter(chrom, filter_dir = genomic_positions_site_filter_dt_data_cloud_zarr_dir):\n",
    "    gcsmap = gcs.get_mapper(filter_dir)\n",
    "    genomic_positions_site_filter_data = zarr.Group(gcsmap, read_only=True)\n",
    "    filter_pass = da.from_zarr(\n",
    "            genomic_positions_site_filter_data[chrom]['variants/filter_pass'])\n",
    "    return filter_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a8094a-d62d-4de2-a816-14409f4e4fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_position(chrom):\n",
    "    store = gcs.get_mapper(\n",
    "        f'gs://vo_afun_release_master_us_central1/v1.0/snp_genotypes/all/sites')\n",
    "    root = zarr.open(store, mode='r')\n",
    "    pos = root[chrom]['variants/POS'][:]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a18322b-6724-4ee2-b615-d147bcebf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_genotypes_positions(chrom, samples_idx, samplesets, posl, posu, \\\n",
    "                                filter_dir = genomic_positions_site_filter_dt_data_cloud_zarr_dir):\n",
    "\n",
    "    # load the genotypes and positions\n",
    "    gt_d = concatenate_along_axis(sampleset_staging_dir, f\"{chrom}/calldata/GT\", samplesets)\n",
    "    gt = allel.GenotypeDaskArray(gt_d)\n",
    "    pos = load_position(chrom)\n",
    "    \n",
    "    if posu==-1:\n",
    "        posu = pos.max()+1\n",
    "        \n",
    "    if posl==-1:\n",
    "        posl = pos.min()\n",
    "    \n",
    "    #load the filter\n",
    "    loc_filt = load_filter(chrom, filter_dir)\n",
    "    \n",
    "    #filter by positions\n",
    "    pos_filt = (pos>=posl) & (pos<posu)\n",
    "    \n",
    "    #apply the filter to positions and genotypes\n",
    "    gt = gt.compress((loc_filt) & (pos_filt), axis=0)\n",
    "    pos = pos[(loc_filt) & (pos_filt)]\n",
    "    \n",
    "    #subset to desired samples \n",
    "    gt = da.take(gt, samples_idx, axis=1)\n",
    "    \n",
    "    return gt, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d55675-4ca5-4381-9ebe-08575c1925f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @functools.lru_cache(maxsize=None)\n",
    "def compute_roh_per_sample(sample_idx, ssets, chrom, min_roh):\n",
    "\n",
    "    #load the filtered genotype\n",
    "    # get_genotype(chrom, ssets, sample=False)\n",
    "    gt, pos = read_in_genotypes_positions(chrom, sample_idx, ssets, posl=-1, posu=-1,)\n",
    "    gv = allel.GenotypeDaskVector(gv)\n",
    "    \n",
    "    #perform the roh computation\n",
    "    #note gt, pos is already filtered by accessibility\n",
    "    df_roh, froh = allel.roh_mhmm(gt, pos, min_roh=min_roh)\n",
    "    \n",
    "    #get roh not at the edge of the segment to avoid double counting\n",
    "    roh_count = len(df_roh[df_roh['is_marginal']==False])\n",
    "    \n",
    "    return roh_count, froh, df_roh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aeaec0-69ca-41a7-b0d1-0fc1873d71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_het_per_sample(sample_idx, ssets, chrom, window_size):\n",
    "\n",
    "    #load the filtered genotype\n",
    "    # get_genotype(chrom, ssets, sample=False)\n",
    "    gt, pos = read_in_genotypes_positions(chrom, sample_idx, ssets, posl=-1, posu=-1,)\n",
    "    gv = allel.GenotypeDaskVector(gv)\n",
    "    \n",
    "    het = gv.is_het().compute()\n",
    "    \n",
    "    #split to windows\n",
    "    het_win, pos_win, cnt_win = allel.windowed_statistic(pos, values=het, statistic=np.mean, size=window_size)\n",
    "    \n",
    "    return het_win, pos_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4223871-5664-4c51-835e-18af991853b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roh_all(meta, chrom, min_roh, ssets):\n",
    "    \n",
    "    for sample_idx in meta.index:\n",
    "        count, frac, df_roh = compute_roh_per_sample([sample_idx], ssets, chrom, min_roh)\n",
    "        meta.loc[sample_idx, [f'ROH_count_{chrom}', f'ROH_frac_{chrom}']] = count, frac\n",
    "        \n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33161e1b-b6c9-48b1-aa1d-7ce6bae8319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roh_per_sample(roh_df, het_win, pos_win, sample_name, chrom):\n",
    "    \n",
    "    \n",
    "    # plotting setup\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.5))\n",
    "    sns.despine(ax=ax, offset=10)\n",
    "\n",
    "    # plot heterozygosity\n",
    "    y = het_win\n",
    "    x = np.mean(pos_win, axis=1)\n",
    "    ax.plot(x, y, linewidth=1.5)\n",
    "    ax.set_ylim(-0.01, 0.04)\n",
    "    ax.set_yticks(np.arange(0, 0.04, 0.02))\n",
    "    ax.set_xlim(0, pos_win.max())\n",
    "    ax.set_xlabel(f'Chromosome {chrom} position (Mbp)', fontsize=7)\n",
    "    ax.set_ylabel('heterozygosity', fontsize=7)\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: f\"{x//1e6:.1f}\"))\n",
    "\n",
    "    # plot roh\n",
    "    xranges = np.column_stack([df_roh.start, df_roh.length])\n",
    "    yrange = (-.008, 0.006)\n",
    "    ax.broken_barh(xranges, yrange, facecolor='#B8B8B8', linewidth=None)\n",
    "\n",
    "    \n",
    "    ax.set_title(f'Heterozygosity and ROHs for {sample_name}')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'ROH_{sample_name}_{chrom}.svg', dpi=300, bbox_inches='tight')    \n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31430ed1-4e38-4a2a-896c-864e7da9e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put meta in order as dask is stored\n",
    "sample_order = concatenate_along_axis(sampleset_staging_dir, \"samples\", samplesets).compute()\n",
    "sample_order = (sample_order[0]).astype(str)\n",
    "meta.set_index('sample_id', inplace=True)\n",
    "meta = meta.loc[sample_order]\n",
    "meta.reset_index(inplace=True)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddae2e-2f08-492f-8f66-401b46eff534",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the ROH computation for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84feaa63-d7f5-499a-a368-ddf32929d688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_X = load_filter('X')\n",
    "n_sites_X = acc_X.sum().compute()\n",
    "acc_2RL = load_filter('2RL')\n",
    "n_sites_2RL = acc_2RL.sum().compute()\n",
    "acc_3RL = load_filter('3RL')\n",
    "n_sites_3RL = acc_3RL.sum().compute()\n",
    "n_sites = n_sites_X + n_sites_2RL + n_sites_3RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a15068c-4192-4d00-96c0-9e778aad15f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_roh = 100_000\n",
    "\n",
    "for chrom in ['2RL', '3RL', 'X']:\n",
    "    meta = compute_roh_all(meta, chrom, min_roh, samplesets)\n",
    "    meta.to_csv(\"results_roh.tsv\", sep='\\t', index=False)\n",
    "    \n",
    "meta['ROH_count'] = meta['ROH_count_2RL'] + meta['ROH_count_3RL'] + meta['ROH_count_X'] \n",
    "meta['ROH_frac'] = meta['ROH_frac_2RL'] * n_sites_2RL/n_sites + meta['ROH_frac_3RL'] * n_sites_3RL/n_sites + meta['ROH_frac_X'] * n_sites_X/n_sites\n",
    "meta.to_csv(\"results_roh.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b994fbf-5162-4281-a845-ef7f3728def0",
   "metadata": {},
   "source": [
    "## Compute ROH for a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013197a-a18e-43e7-b57d-f27e804fca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'VBS24196'\n",
    "chrom = '2RL'\n",
    "window_size=100_000\n",
    "sample_idx = meta.loc[meta.VBS_sample_id==sample_name].index\n",
    "count, frac, df_roh = compute_roh_per_sample([sample_idx], samplesets, chrom, min_roh)\n",
    "het_win, pos_win = compute_het_per_sample([sample_idx], samplesets, chrom, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65cc79-8c4f-44a6-88e8-4ecd0942be9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b0e6e-0427-4c92-9112-7825ffb11c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-mgenv-6.0.6",
   "language": "python",
   "name": "conda-env-global-global-mgenv-6.0.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
