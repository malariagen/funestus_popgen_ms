{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e901eb-e1ab-4fc8-9ac3-3148a8167805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import zarr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import allel\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False}) # Silence large chunk warnings\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "from dask_gateway import Gateway\n",
    "import functools\n",
    "import numcodecs\n",
    "from fsspec.implementations.zip import ZipFileSystem\n",
    "from collections.abc import Mapping\n",
    "import gcsfs\n",
    "import numba\n",
    "import psutil\n",
    "from humanize import naturalsize\n",
    "\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from pyprojroot import here\n",
    "from bokeh.plotting import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01f658-cc9d-4af9-ad17-e7256258ea9d",
   "metadata": {},
   "source": [
    "### Connect to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112507b-08d0-49a3-b46f-39b9d70e1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded9b92-0084-4456-a3e2-0326f4cc6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs.ls('vo_afun_release_master_us_central1')[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907e16c-1cdf-4d00-9bd9-e3b1af2f0a76",
   "metadata": {},
   "source": [
    "### Set up data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d00d95-8fb0-4d58-8f5d-20fa741d493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_root = Path('vo_afun_release_master_us_central1')\n",
    "vo_afun_staging = Path(production_root, 'v1.0')\n",
    "sampleset_staging_dir = Path(vo_afun_staging, 'snp_genotypes', 'all')\n",
    "\n",
    "#Decision tree or static filters\n",
    "genomic_positions_site_filter_dt_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/dt_20200416/funestus'\n",
    "genomic_positions_site_filter_sc_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/sc_20220908/funestus'\n",
    "\n",
    "repo_clone_path = here()\n",
    "release_config_path = repo_clone_path / 'tracking' / 'release' / 'v1.0' / 'config.yml'\n",
    "\n",
    "with open(release_config_path) as fh:\n",
    "    config = yaml.load(fh, Loader=yaml.BaseLoader)\n",
    "    \n",
    "samplesets = config[\"sample_sets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938e6748-a8fc-4b4a-b5d4-72b118c25b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'geographic_cohort', 'geographic_cohort_colour',\n",
       "       'geographic_cohort_shape', 'PCA_cohort', 'PCA_cohort_colour',\n",
       "       'mitochondrial_id', 'karyotype_3La', 'karyotype_3Ra', 'karyotype_3Rb',\n",
       "       'karyotype_2Ra', 'karyotype_2Rh', 'median_coverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(\"../../metadata/supp1_tab2.csv\")\n",
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3e46c-3855-42e8-8155-95a02f51a28b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df2fd2b-bdbf-4248-9565-2cc9cc9622be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def a1(n):\n",
    "    return np.sum(1/np.arange(1,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fd2d6a-5e91-408b-bd42-8e8c7cb314bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def a2(n):\n",
    "    return np.sum(1/(np.arange(1,n)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e971d89-713b-437d-83ef-778623893572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def b1(n):\n",
    "    return (n+1)/(3*(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528a8db8-3712-42a7-8078-0c1a9cf184f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def b2(n):\n",
    "    return 2*(n**2+n+3)/(9*n*(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7687c9f0-0ab7-467f-a987-1f78a1ec5454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c1(n):\n",
    "    return b1(n) - (1/a1(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24413ea2-9458-4aa9-8746-20a2618ce853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c2(n):\n",
    "    return b2(n) - ((n + 2) / (a1(n) * n)) + (a2(n) / (a1(n)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61d611c-cc7a-4fd4-86ba-234838a5be39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def e1(n):\n",
    "    return c1(n)/a1(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221e735d-4e1e-44a8-90de-558a503f09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def e2(n):\n",
    "    return c2(n)/(a1(n)**2+a2(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd35940-21f0-4fe9-ab8f-403d169fed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single array from field/chrom/sampleset\n",
    "# internal path for calldata is chrom/calldata/field\n",
    "# sampleset_calldata = sampleset_staging_dir / sset\n",
    "# sampleset is needed to load species spec.\n",
    "def load_single_field(zarr_path, internal_path, sset, exclude_males=False, samples=None):\n",
    "      \n",
    "    inz = zarr.group(is_gcloud(zarr_path), overwrite=False)\n",
    "    \n",
    "    oo = da.from_zarr(inz[internal_path])  \n",
    "    \n",
    "    if oo.ndim == 1:\n",
    "        oo = oo.reshape((1, -1))\n",
    "           \n",
    "    return oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2d87e7-e90f-4ecc-8975-f89686b5ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General function to concatenate data.\n",
    "## Selected chunk size may be more appropriate for some than others.\n",
    "def concatenate_along_axis(base_dir, internal_path, req_samplesets):\n",
    "    \n",
    "    # work out shape\n",
    "    data = [load_single_field(base_dir / ss, internal_path, ss) for ss in req_samplesets]\n",
    "    \n",
    "    return da.concatenate(data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af0f368-c3e5-4b4e-9481-f42730b63708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gcloud(path):\n",
    "    \n",
    "    try: \n",
    "        return gcs.get_mapper(path.as_posix())\n",
    "    except NameError as e:\n",
    "        return path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9ffc83-6894-4577-9ca3-a6ed36553fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter(chrom, filter_dir = genomic_positions_site_filter_sc_data_cloud_zarr_dir):\n",
    "    gcsmap = gcs.get_mapper(filter_dir)\n",
    "    genomic_positions_site_filter_data = zarr.Group(gcsmap, read_only=True)\n",
    "    filter_pass = da.from_zarr(\n",
    "            genomic_positions_site_filter_data[chrom]['variants/filter_pass'])\n",
    "    return filter_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30bca2e-58e4-4d13-bb07-38a08b23706a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_position(chrom):\n",
    "    store = gcs.get_mapper(\n",
    "        f'gs://vo_afun_release_master_us_central1/v1.0/snp_genotypes/all/sites')\n",
    "    root = zarr.open(store, mode='r')\n",
    "    pos = root[chrom]['variants/POS'][:]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102d82b6-f549-43e6-ba9b-392c3204a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_genotypes_positions(chrom, samples_idx, samplesets, posl, posu, \\\n",
    "                                filter_dir = genomic_positions_site_filter_sc_data_cloud_zarr_dir):\n",
    "\n",
    "    # load the genotypes and positions\n",
    "    gt_d = concatenate_along_axis(sampleset_staging_dir, f\"{chrom}/calldata/GT\", samplesets)\n",
    "    gt = allel.GenotypeDaskArray(gt_d)\n",
    "    pos = load_position(chrom)\n",
    "    \n",
    "    if posu==-1:\n",
    "        posu = pos.max()+1\n",
    "        \n",
    "    if posl==-1:\n",
    "        posl = pos.min()\n",
    "    \n",
    "    #load the filter\n",
    "    loc_filt = load_filter(chrom, filter_dir)\n",
    "    \n",
    "    #filter by positions\n",
    "    pos_filt = (pos>=posl) & (pos<posu)\n",
    "    \n",
    "    #apply the filter to positions and genotypes\n",
    "    gt = gt.compress((loc_filt) & (pos_filt), axis=0)\n",
    "    pos = pos[(loc_filt) & (pos_filt)]\n",
    "    \n",
    "    #subset to desired samples \n",
    "    gt = da.take(gt, samples_idx, axis=1)\n",
    "    \n",
    "    return gt, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c759236-e1ff-4985-9f04-c4ab123e7307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_per_window(values, window_size):\n",
    "    n_windows = len(values)//window_size\n",
    "    vals = np.zeros(n_windows)\n",
    "    for w in np.arange(n_windows):\n",
    "        vals[w] = np.nanmean(values[w*window_size:(w+1)*window_size])\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffdf8425-8eb4-4101-bef7-f7ecd68bca83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_per_window(values, window_size):\n",
    "    n_windows = len(values)//window_size\n",
    "    vals = np.zeros(n_windows)\n",
    "    for w in np.arange(n_windows):\n",
    "        vals[w] = np.nansum(values[w*window_size:(w+1)*window_size])\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbc22c2-009c-4c09-99a2-95bc9b380096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_tajimas_d(chrom, samples_idx, posl, posu, window_size, missing_frac,\\\n",
    "                     samplesets):\n",
    "    \n",
    "    #read in genotypes\n",
    "    gt, pos = read_in_genotypes_positions(chrom, samples_idx, samplesets, posl=posl, posu=posu)\n",
    "    \n",
    "    #count alleles \n",
    "    ac = gt.count_alleles(max_allele=3)\n",
    "    \n",
    "    #filters for missingness, biallelism and maf\n",
    "    missing_filter = ac.sum(axis=1) >= (1-missing_frac)*2*len(samples_idx)\n",
    "    \n",
    "    #get filtered allele counts\n",
    "    ac_f = ac.compress(missing_filter, axis=0)\n",
    "    pos_f = pos[missing_filter]\n",
    "    \n",
    "    #assess which sites are segregating\n",
    "    seg_f = ac_f.is_segregating()\n",
    "    \n",
    "    #compute pi\n",
    "    mpd = allel.mean_pairwise_difference(ac_f)\n",
    "    \n",
    "    #sum pi per window\n",
    "    windowed_mpd = sum_per_window(mpd, window_size)\n",
    "    window_centers = mean_per_window(pos_f, window_size)\n",
    "    \n",
    "    #compute number of segregating sites per window\n",
    "    windowed_S = count_segregating_per_window(seg_f, window_size)\n",
    "    \n",
    "    #compute constants\n",
    "    #this assumes no missing data - actual values will be slightly off \n",
    "    #but scikit allele does the same\n",
    "    n_alleles = len(samples_idx) * 2\n",
    "    ch_a1 = a1(n_alleles)\n",
    "    ch_e1 = e1(n_alleles)\n",
    "    ch_e2 = e2(n_alleles)\n",
    "    \n",
    "    #compute tajima's D\n",
    "    d = windowed_mpd - windowed_S/ch_a1\n",
    "    std = np.sqrt((ch_e1 * windowed_S) + (ch_e2 * windowed_S * (windowed_S - 1)))\n",
    "    D = d/std\n",
    "    \n",
    "    #get starting position new reading frame\n",
    "    end_pos = pos_f[len(D)*window_size]\n",
    "    \n",
    "    return D, windowed_mpd, window_centers, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a5daa8-185a-49d7-a12c-13c6d583d993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_segregating_per_window(seg_f, window_size):\n",
    "    \n",
    "    #get the positions of segregating sites\n",
    "    pos_s = np.arange(seg_f.shape[0])[seg_f.compute()]\n",
    "    \n",
    "    n_windows = seg_f.shape[0]//window_size\n",
    "    start_locs = np.searchsorted(pos_s, np.arange(n_windows)*window_size+1)\n",
    "    stop_locs = np.searchsorted(pos_s, np.arange(1,n_windows+1)*window_size, side='right')\n",
    "    locs = np.column_stack((start_locs, stop_locs))\n",
    "    counts = np.diff(locs, axis=1).reshape(-1)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fdbc156-af0c-43d7-8e5c-7cb37f50c658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loop_through_reading_frames(chrom, samples_idx, samplesets, outdir, cohortname,\\\n",
    "                                reading_frame_size, window_size, missing_frac):\n",
    "    \n",
    "    chrom_size = load_position(chrom).max()\n",
    "    \n",
    "    taj_d, mpd, windows, rf_start = compute_tajimas_d(chrom, samples_idx, 0, reading_frame_size, window_size=window_size, \\\n",
    "                                    missing_frac=missing_frac, samplesets=samplesets)\n",
    "    rf_end = reading_frame_size\n",
    "    while rf_end < chrom_size:\n",
    "        rf_end = rf_start + reading_frame_size\n",
    "        taj_d_rf, mpd_rf, windows_rf, rf_start = compute_tajimas_d_downsampled(chrom, samples_idx, rf_start, rf_end, window_size, missing_frac,\\\n",
    "                     samplesets)\n",
    "        \n",
    "        taj_d = np.concatenate((taj_d, taj_d_rf))\n",
    "        mpd = np.concatenate((mpd, mpd_rf))\n",
    "        windows = np.concatenate((windows, windows_rf))\n",
    "        np.save(f'{outdir}/{chrom}_{cohortname}_tajima_d.npy', taj_d)\n",
    "        np.save(f'{outdir}/{chrom}_{cohortname}_pi.npy', mpd)\n",
    "        np.save(f'{outdir}/{chrom}_{cohortname}_windows.npy', windows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ef527f8-d8d8-4938-933d-7ff286a27743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_tajima_d_all_cohorts(chrom, cohorts, meta, outdir, size=30, samplesets=samplesets, \\\n",
    "                          reading_frame_size=10_000_000, window_size=20_000, missing_frac=0.05):\n",
    "    \n",
    "    for cohort in cohorts:\n",
    "        samples_idx = meta.loc[(meta.geographic_cohort==cohort) & (meta.subset_3=='Y')].index\n",
    "        loop_through_reading_frames(chrom, samples_idx, samplesets, outdir, cohort,\n",
    "                                    reading_frame_size, window_size, missing_frac)\n",
    "        print(f\"On chromosome {chrom} cohort {cohort} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5470d5d-ca41-4f23-9aa3-4fe4605355ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put meta in order as dask is stored\n",
    "sample_order = concatenate_along_axis(sampleset_staging_dir, \"samples\", samplesets).compute()\n",
    "sample_order = (sample_order[0]).astype(str)\n",
    "meta.set_index('VBS_sample_id', inplace=True)\n",
    "meta = meta.loc[sample_order]\n",
    "meta.reset_index(inplace=True)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc340e6-d6aa-420f-bb9a-95edd822b36e",
   "metadata": {},
   "source": [
    "### Set up dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd257b6f-e8a7-4ea0-ac86-875ab39750a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a362ed1-654d-4cc2-90ad-992ccb18dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50161f353c974b68879884d695c8df06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gateway = Gateway()\n",
    "conda_prefix = os.environ[\"CONDA_PREFIX\"]\n",
    "current_environment = 'global/'+conda_prefix.split('/')[5]\n",
    "cluster = gateway.new_cluster(\n",
    "    profile='standard', \n",
    "    conda_environment = current_environment,\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3fcf660-b618-45aa-860e-a99aa3a865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6311c415-bbd9-4b32-8ef0-87c11afa668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52e7b4cc-56b3-4807-b822-ff7503e41a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ghana_Northern-Region', 'Gabon_Haut-Ogooue', 'CAR_Ombella-MPoko',\n",
       "       'Cameroon_Adamawa', 'Ghana_Ashanti-Region',\n",
       "       'Malawi_Southern-Region', 'Mozambique_Maputo',\n",
       "       'Uganda_Eastern-Region', 'Benin_Atlantique-Dept', 'DRC_Kinshasa',\n",
       "       'Nigeria_Ogun-State', 'Zambia_Eastern-Prov', 'Kenya_Nyanza-Prov',\n",
       "       'Kenya_Western-Prov', 'Tanzania_Morogoro-Region', 'DRC_Haut-Uele',\n",
       "       'Mozambique_Cabo-Delgado'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts = meta.loc[meta.subset_3=='Y', 'geographic_cohort'].unique()\n",
    "cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a1e8fdb-f319-4a7b-acaf-e4f6dc3be5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On chromosome X cohort Ghana_Northern-Region done\n",
      "On chromosome X cohort Gabon_Haut-Ogooue done\n",
      "On chromosome X cohort Cameroon_Adamawa done\n",
      "On chromosome X cohort Ghana_Ashanti-Region done\n",
      "On chromosome X cohort Mozambique_Maputo done\n",
      "On chromosome X cohort Uganda_Eastern-Region done\n",
      "On chromosome X cohort Benin_Atlantique-Dept done\n",
      "On chromosome X cohort DRC_Kinshasa done\n",
      "On chromosome X cohort Nigeria_Ogun-State done\n",
      "On chromosome X cohort Zambia_Eastern-Prov done\n",
      "On chromosome X cohort Kenya_Nyanza-Prov done\n",
      "On chromosome X cohort DRC_Haut-Uele done\n",
      "On chromosome X cohort Mozambique_Cabo-Delgado done\n"
     ]
    }
   ],
   "source": [
    "compute_tajima_d_all_cohorts('X', cohorts, meta, 'tajima_d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33e7e75a-ccb2-45e0-a1d5-b61921ae01bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On chromosome 3RL cohort Ghana_Northern-Region done\n",
      "On chromosome 3RL cohort Gabon_Haut-Ogooue done\n",
      "On chromosome 3RL cohort Cameroon_Adamawa done\n",
      "On chromosome 3RL cohort Ghana_Ashanti-Region done\n",
      "On chromosome 3RL cohort Mozambique_Maputo done\n",
      "On chromosome 3RL cohort Uganda_Eastern-Region done\n",
      "On chromosome 3RL cohort Benin_Atlantique-Dept done\n",
      "On chromosome 3RL cohort DRC_Kinshasa done\n",
      "On chromosome 3RL cohort Nigeria_Ogun-State done\n",
      "On chromosome 3RL cohort Zambia_Eastern-Prov done\n",
      "On chromosome 3RL cohort Kenya_Nyanza-Prov done\n",
      "On chromosome 3RL cohort DRC_Haut-Uele done\n",
      "On chromosome 3RL cohort Mozambique_Cabo-Delgado done\n"
     ]
    }
   ],
   "source": [
    "compute_tajima_d_all_cohorts('3RL', cohorts, meta, 'tajima_d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bf67412-cfdf-4f4f-a876-0a798d422259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On chromosome 2RL cohort Ghana_Northern-Region done\n",
      "On chromosome 2RL cohort Gabon_Haut-Ogooue done\n",
      "On chromosome 2RL cohort Cameroon_Adamawa done\n",
      "On chromosome 2RL cohort Ghana_Ashanti-Region done\n",
      "On chromosome 2RL cohort Mozambique_Maputo done\n",
      "On chromosome 2RL cohort Uganda_Eastern-Region done\n",
      "On chromosome 2RL cohort Benin_Atlantique-Dept done\n",
      "On chromosome 2RL cohort DRC_Kinshasa done\n",
      "On chromosome 2RL cohort Nigeria_Ogun-State done\n",
      "On chromosome 2RL cohort Zambia_Eastern-Prov done\n",
      "On chromosome 2RL cohort Kenya_Nyanza-Prov done\n",
      "On chromosome 2RL cohort DRC_Haut-Uele done\n",
      "On chromosome 2RL cohort Mozambique_Cabo-Delgado done\n"
     ]
    }
   ],
   "source": [
    "compute_tajima_d_all_cohorts('2RL', cohorts, meta, 'tajima_d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef98611-6522-43b0-bde5-2b5b1c77e69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a330bd-fcd4-4512-bcb7-a91b239161cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea19ef-5bfc-4095-aff6-2d50713a6cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75ebbf06-b2f7-4046-9372-3e1cae3050fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7c28a1-9e06-4ba0-b644-8f2ef96f7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for report in gateway.list_clusters():\n",
    "    gateway.connect(report.name).shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d242d8-2cdc-4d41-b081-2a27db589d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default *",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
