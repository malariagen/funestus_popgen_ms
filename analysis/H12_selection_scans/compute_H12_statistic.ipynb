{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970092a9-33c1-410c-863c-0b8d12ae73ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import zarr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import allel\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False}) # Silence large chunk warnings\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "from dask_gateway import Gateway\n",
    "import functools\n",
    "import numcodecs\n",
    "from fsspec.implementations.zip import ZipFileSystem\n",
    "from collections.abc import Mapping\n",
    "import gcsfs\n",
    "import numba\n",
    "import psutil\n",
    "from humanize import naturalsize\n",
    "\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from pyprojroot import here\n",
    "from bokeh.plotting import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda46648-7915-4482-95e6-8124f88dc723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <table class=\"malariagen-af1\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\" colspan=\"2\">MalariaGEN Af1 API client</th>\n",
       "                    </tr>\n",
       "                    <tr><td colspan=\"2\" style=\"text-align: left\">\n",
       "                        Please note that data are subject to terms of use,\n",
       "                        for more information see <a href=\"https://www.malariagen.net/data\">\n",
       "                        the MalariaGEN website</a> or contact data@malariagen.net.\n",
       "                    </td></tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Storage URL\n",
       "                        </th>\n",
       "                        <td>gs://vo_afun_release/</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Data releases available\n",
       "                        </th>\n",
       "                        <td>1.0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Results cache\n",
       "                        </th>\n",
       "                        <td>None</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Cohorts analysis\n",
       "                        </th>\n",
       "                        <td>20221129</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Site filters analysis\n",
       "                        </th>\n",
       "                        <td>dt_20200416</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Software version\n",
       "                        </th>\n",
       "                        <td>malariagen_data 7.13.0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th style=\"text-align: left\">\n",
       "                            Client location\n",
       "                        </th>\n",
       "                        <td>unknown</td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        "
      ],
      "text/plain": [
       "<MalariaGEN Af1 API client>\n",
       "Storage URL             : gs://vo_afun_release/\n",
       "Data releases available : 1.0\n",
       "Results cache           : None\n",
       "Cohorts analysis        : 20221129\n",
       "Site filters analysis   : dt_20200416\n",
       "Software version        : malariagen_data 7.13.0\n",
       "Client location         : unknown\n",
       "---\n",
       "Please note that data are subject to terms of use,\n",
       "for more information see https://www.malariagen.net/data\n",
       "or contact data@malariagen.net."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access the data from the cloud.\n",
    "af1 = malariagen_data.Af1()\n",
    "af1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e70117-c066-4e99-bd14-f4cb57b01cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9aba508-ac2f-4bf5-a3bb-c4c5837835e9",
   "metadata": {},
   "source": [
    "### Connect to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726328bf-9e36-45e5-901b-79051b04bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c694d57-9901-44e4-922b-53387d3e1b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcs.ls('vo_afun_release_master_us_central1')[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081bd6c-e194-4c81-99e8-6530b24a2084",
   "metadata": {},
   "source": [
    "### Set up data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd613d3-f0c6-4c4d-a7e9-e112086edef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "production_root = Path('vo_afun_release_master_us_central1')\n",
    "vo_afun_staging = Path(production_root, 'v1.0')\n",
    "sampleset_staging_dir = Path(vo_afun_staging, 'snp_genotypes', 'all')\n",
    "haplotypes_dir = Path(vo_afun_staging, 'snp_haplotypes')\n",
    "\n",
    "#Decision tree or static filters\n",
    "genomic_positions_site_filter_dt_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/dt_20200416/funestus'\n",
    "genomic_positions_site_filter_sc_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/sc_20220908/funestus'\n",
    "\n",
    "repo_clone_path = here()\n",
    "release_config_path = repo_clone_path / 'analysis' / 'config.yml'\n",
    "\n",
    "with open(release_config_path) as fh:\n",
    "    config = yaml.load(fh, Loader=yaml.BaseLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e09a5-4e1f-4233-9a0d-1c7e5e397607",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"../../metadata/supp1_tab2.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddcc3d-87ac-43c1-9c74-2402e36fe41e",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b5052f-5415-4f96-b5d6-97fb1c63ba01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "analysis = 'funestus'\n",
    "chromosomes = ['2RL', '3RL', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2741b3b-3bdc-4804-b1d3-a4bf9041aade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1229-VO-GH-DADZIE-VMF00095',\n",
       " '1230-VO-GA-CF-AYALA-VMF00045',\n",
       " '1231-VO-MULTI-WONDJI-VMF00043',\n",
       " '1232-VO-KE-OCHOMO-VMF00044',\n",
       " '1235-VO-MZ-PAAIJMANS-VMF00094',\n",
       " '1236-VO-TZ-OKUMU-VMF00090',\n",
       " '1240-VO-CD-KOEKEMOER-VMF00099',\n",
       " '1240-VO-MZ-KOEKEMOER-VMF00101']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the sample sets\n",
    "sample_sets = af1.sample_sets(release=f\"{release}\")['sample_set'].tolist()\n",
    "sample_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea1c2c2-14c4-4784-be60-75e8092eef70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_sizes=(100, 200, 300, 500, 700, 1000, 2000, 3000, 4000)\n",
    "geographic_cohorts = list(metadata.geographic_cohort.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c029cf-79f4-45af-b6c9-26988637e086",
   "metadata": {},
   "source": [
    "### Connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cef8778-609b-44d9-9d6c-f2ba1f5fadd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gateway = Gateway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1621c2-72db-472b-ba2a-fbd082887f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check if any cluster is currently running\n",
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9937dc-ef7c-4b19-bb55-b61752d970bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gateway = Gateway()\n",
    "conda_prefix = os.environ[\"CONDA_PREFIX\"]\n",
    "current_environment = 'global/'+conda_prefix.split('/')[5]\n",
    "cluster = gateway.new_cluster(\n",
    "    profile='standard', \n",
    "    conda_environment = current_environment,\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "153bd5e7-50e9-43a5-be1d-e34ddce4bc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(50)\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d5483-c5ac-4fa2-a1b1-0c3364802c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc0b479-9c39-4d89-96e6-52afd1bb2b00",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62ea993b-4b02-401a-88b9-a0fe70e7e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def da_from_zarr(z, inline_array, chunks=\"auto\"):\n",
    "    \"\"\"Utility function for turning a zarr array into a dask array.\n",
    "    \"\"\"\n",
    "    if chunks == \"native\" or z.dtype == object:\n",
    "        # N.B., dask does not support \"auto\" chunks for arrays with object dtype\n",
    "        chunks = z.chunks\n",
    "    kwargs = dict(chunks=chunks, fancy=False, lock=False, inline_array=inline_array)\n",
    "    try:\n",
    "        d = da.from_array(z, **kwargs)\n",
    "    except TypeError:\n",
    "        # only later versions of dask support inline_array argument\n",
    "        del kwargs[\"inline_array\"]\n",
    "        d = da.from_array(z, **kwargs)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28426184-a2ca-4649-aa14-4274439cc298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xarray_concat(datasets, dim, data_vars=\"minimal\", coords=\"minimal\", compat=\"override\", join=\"override\", **kwargs):\n",
    "    if len(datasets) == 1:\n",
    "        return datasets[0]\n",
    "    else:\n",
    "        return xr.concat(datasets, dim=dim, data_vars=data_vars, coords=coords, compat=compat, join=join, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b9e763b-a74c-4244-99cd-41b2a279fdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_position(chrom):\n",
    "    store = gcs.get_mapper(\n",
    "        f'gs://vo_afun_release_master_us_central1/v1.0/snp_genotypes/all/sites')\n",
    "    root = zarr.open(store, mode='r')\n",
    "    pos = root[chrom]['variants/POS'][:]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b3bec1-5404-4266-bf15-82da20af9b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_haplotypes(sample_set, analysis=analysis):  \n",
    "    zarr_path = f\"{haplotypes_dir}/{sample_set}/{analysis}/zarr\"\n",
    "    store = gcs.get_mapper(zarr_path) \n",
    "    root = zarr.open_consolidated(store = store,)    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abb378b6-03a5-44bf-a681-0e66a0995465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_haplotype_sites(analysis=analysis):       \n",
    "    zarr_path = f\"{haplotypes_dir}/sites/{analysis}/zarr\"\n",
    "    store = gcs.get_mapper(zarr_path)    \n",
    "    root = zarr.open_consolidated(store = store,)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83f1a142-fdc0-4f29-9b7e-db53e00b91de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def haplotypes_dataset(*, chrom, sample_set, analysis, inline_array, chunks):\n",
    "    \n",
    "    #open the zarr files\n",
    "    root = open_haplotypes(sample_set=sample_set, analysis=analysis)\n",
    "    sites = open_haplotype_sites(analysis=analysis)\n",
    "\n",
    "    # some sample sets have no data for a given analysis, handle this\n",
    "    if root is None:\n",
    "        return None\n",
    "\n",
    "    coords = dict()\n",
    "    data_vars = dict()\n",
    "\n",
    "    #load variant position\n",
    "    pos = sites[f\"{chrom}/variants/POS\"]\n",
    "    coords[\"variant_position\"] = ([\"variants\"], da_from_zarr(pos, inline_array=inline_array, chunks=chunks),)\n",
    "\n",
    "    #load variant_contig\n",
    "    chrom_index = chromosomes.index(chrom)\n",
    "    coords[\"variant_contig\"] = ([\"variants\"], da.full_like(pos, fill_value=chrom_index, dtype=\"u1\"),)\n",
    "\n",
    "    #load variant allele\n",
    "    ref = da_from_zarr(sites[f\"{chrom}/variants/REF\"], inline_array=inline_array, chunks=chunks)\n",
    "    alt = da_from_zarr(sites[f\"{chrom}/variants/ALT\"], inline_array=inline_array, chunks=chunks)\n",
    "    variant_allele = da.hstack([ref[:, None], alt[:, None]])\n",
    "    data_vars[\"variant_allele\"] = [\"variants\", \"alleles\"], variant_allele\n",
    "\n",
    "    #load call_genotype\n",
    "    data_vars[\"call_genotype\"] = ([\"variants\", \"samples\", \"ploidy\"],\n",
    "        da_from_zarr(root[f\"{chrom}/calldata/GT\"], inline_array=inline_array, chunks=chunks),)\n",
    "\n",
    "    #load sample arrays\n",
    "    coords[\"sample_id\"] = ([\"samples\"], da_from_zarr(root[\"samples\"], inline_array=inline_array, chunks=chunks),)\n",
    "\n",
    "    #set up attributes\n",
    "    attrs = {\"contigs\": chrom}\n",
    "\n",
    "    #create a dataset\")\n",
    "    ds = xr.Dataset(data_vars=data_vars, coords=coords, attrs=attrs)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfe524f2-1811-4a40-bf7f-77dd3286fc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def haplotypes(chrom, analysis=analysis, sample_sets=None, sample_query=None, inline_array=True,\n",
    "    chunks=\"native\", cohort_size=None, random_seed=42):\n",
    "    \n",
    "    \"\"\"Access haplotype data.\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray.Dataset\n",
    "        A dataset of haplotypes and associated data.\n",
    "    \"\"\" \n",
    "        \n",
    "    ##build datasets\n",
    "    lx = []\n",
    "    for r in chrom:\n",
    "        ly = []\n",
    "\n",
    "        for s in sample_sets:\n",
    "            y = haplotypes_dataset(chrom=chrom, sample_set=s, analysis=analysis,\n",
    "                inline_array=inline_array, chunks=chunks,)\n",
    "            \n",
    "            if y is not None:\n",
    "                ly.append(y)\n",
    "\n",
    "        if len(ly) == 0:\n",
    "            # debug(\"early out, no data for given sample sets and analysis\")\n",
    "            return None\n",
    "\n",
    "        #concatenate data from multiple sample sets\n",
    "        x = xarray_concat(ly, dim=\"samples\")\n",
    "\n",
    "        lx.append(x)\n",
    "\n",
    "    #concatenate data from multiple regions\n",
    "    ds = xarray_concat(lx, dim=\"variants\")\n",
    "\n",
    "    #handle sample query\n",
    "    if sample_query is not None:\n",
    "\n",
    "        #load sample metadata\n",
    "        df_samples = af1.sample_metadata(sample_sets=sample_sets)\n",
    "\n",
    "        #align sample metadata with haplotypes\n",
    "        phased_samples = ds[\"sample_id\"].values.tolist()\n",
    "        df_samples_phased = (\n",
    "            df_samples.set_index(\"sample_id\").loc[phased_samples].reset_index()\n",
    "        )\n",
    "\n",
    "        #apply the query\n",
    "        loc_samples = df_samples_phased.eval(sample_query).values\n",
    "        if np.count_nonzero(loc_samples) == 0:\n",
    "            raise ValueError(f\"No samples found for query {sample_query!r}\")\n",
    "        ds = ds.isel(samples=loc_samples)\n",
    "\n",
    "    #handle cohort size\")\n",
    "    if cohort_size is not None:\n",
    "        n_samples = ds.dims[\"samples\"]\n",
    "        if n_samples < cohort_size:\n",
    "            raise ValueError(\n",
    "                f\"not enough samples ({n_samples}) for cohort size ({cohort_size})\"\n",
    "            )\n",
    "        rng = np.random.default_rng(seed=random_seed)\n",
    "        loc_downsample = rng.choice(n_samples, size=cohort_size, replace=False)\n",
    "        loc_downsample.sort()\n",
    "        ds = ds.isel(samples=loc_downsample)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae9fc9a7-5550-4ab4-a652-a49c57196fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import functions for plotting. Modified to allow concat of chromosome arms.\n",
    "# @functools.lru_cache(maxsize=None)\n",
    "def load_haplotypes(chrom, analysis, cohort_query, cohort_set, sample_sets=sample_sets, downsample=30, seed=42):\n",
    "    \n",
    "    if chrom in af1.contigs:\n",
    "        print(\"accessing single chromosome arm for cohort \" + cohort_query)\n",
    "        # access haplotypes\n",
    "        ds_haps = haplotypes(chrom=chrom, sample_sets=sample_sets, analysis=analysis)\n",
    "        pos = ds_haps[\"variant_position\"].values\n",
    "        gt = allel.GenotypeDaskArray(ds_haps['call_genotype'].data)   \n",
    "\n",
    "        # access sample metadata and align to haplotypes\n",
    "        cohorts_meta_df = pd.read_csv(metadata_path)\n",
    "        samples_phased = ds_haps['sample_id'].values  # dask computation happens here\n",
    "        cohorts_meta_df_phased = cohorts_meta_df.set_index(\"VBS_sample_id\").loc[samples_phased].reset_index()\n",
    "\n",
    "        # apply cohort query #find samples that match a cohort in the admin query\n",
    "        samples = cohorts_meta_df_phased.loc[cohorts_meta_df_phased[cohort_set]==cohort_query]\n",
    "\n",
    "        #get the index of those values\n",
    "        cohort_index = samples.index.values\n",
    "        \n",
    "        #downsample\n",
    "        if len(cohort_index) >= downsample:\n",
    "            np.random.seed(seed)\n",
    "            cohort_index = np.random.choice(cohort_index, size=downsample, replace=False)\n",
    "            cohort_index.sort()\n",
    "\n",
    "        gt_cohort = gt.take(cohort_index, axis=1)\n",
    "        ht_cohort = gt_cohort.to_haplotypes().compute()  # dask computation happens here\n",
    "\n",
    "    return pos, ht_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e5b9810-47af-40a6-af05-81719d3dd40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @functools.lru_cache(maxsize=None)\n",
    "def h12_calibration(chrom, analysis, cohort_query, cohort_set, window_sizes, \n",
    "                    sample_sets, downsample=30, seed=42):\n",
    "        \n",
    "        print(\"load haplotypes\")\n",
    "        pos, ht_cohort = load_haplotypes(chrom=chrom, analysis=analysis,cohort_query=cohort_query,\n",
    "            cohort_set=cohort_set, sample_sets=sample_sets, downsample=downsample, seed=seed)\n",
    "        \n",
    "        print(\"starting calibration runs\")\n",
    "        calibration_runs = list()\n",
    "        for window_size in window_sizes:\n",
    "            print(f\"compute H12 at window size {window_size}\")\n",
    "            h1, h12, h123, h2_h1 = allel.moving_garud_h(ht_cohort, size=window_size)\n",
    "            calibration_runs.append(h12)\n",
    "\n",
    "        return calibration_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a44e3-affc-4db6-89ab-112449174281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78e35a88-f0fa-4f46-820f-36f835930c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_h12_calibration(chrom, analysis, cohort_query, cohort_set, window_sizes, sample_sets, downsample=30, seed=42,title=None):\n",
    "    # get H12 values\n",
    "    # with ProgressBar():\n",
    "    calibration_runs = h12_calibration(chrom=chrom, analysis=analysis, cohort_query=cohort_query, cohort_set=cohort_set,\n",
    "        sample_sets=sample_sets, window_sizes=window_sizes, downsample=downsample, seed=seed)\n",
    "    \n",
    "    # compute summaries\n",
    "    q50 = [np.median(h12) for h12 in calibration_runs]\n",
    "    q25 = [np.percentile(h12, 25) for h12 in calibration_runs] \n",
    "    q75 = [np.percentile(h12, 75) for h12 in calibration_runs] \n",
    "    q05 = [np.percentile(h12, 5) for h12 in calibration_runs] \n",
    "    q95 = [np.percentile(h12, 95) for h12 in calibration_runs]\n",
    "    \n",
    "    # make a plot\n",
    "    fig, ax = plt.subplots()\n",
    "    x = window_sizes\n",
    "    y = q50\n",
    "    ax.grid()\n",
    "    ax.fill_between(x, q05, q95, color='#bbbbff', label=\"5-95%\") \n",
    "    ax.fill_between(x, q25, q75, color='#7777ff', label=\"25-75%\")\n",
    "    ax.plot(x, q50, color='k', lw=2, linestyle=\"-\", marker=\"o\", label=\"median\") \n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks(window_sizes) \n",
    "    ax.set_xticklabels(window_sizes) \n",
    "    ax.set_xlabel(\"Window size (no. SNPs)\") \n",
    "    ax.set_ylabel(\"H12\")\n",
    "    ax.legend() \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if cohort_set=='karyotype_3Ra':\n",
    "        sanitized_cohort_query = re.sub(r'\\W+', '_', cohort_query)\n",
    "        plt.savefig(f\"plots/{chrom}_{sanitized_cohort_query}_h12_calibration\")\n",
    "    else:\n",
    "        plt.savefig(f\"plots/{chrom}_{cohort_query}_h12_calibration\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00062817-9992-4f17-9bea-abbd17bc1802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=None)\n",
    "def h12_gwss(chrom, analysis, cohort_query, cohort_set, window_size, sample_sets, downsample=30, seed=42):\n",
    "\n",
    "    print(\"load haplotypes\") \n",
    "    pos, ht = load_haplotypes(chrom=chrom, analysis=analysis, cohort_query=cohort_query, cohort_set=cohort_set, sample_sets=sample_sets, downsample=downsample, seed=seed)\n",
    "    \n",
    "    print(f\"compute H12 at window size {window_size}\")\n",
    "    h1, h12, h123, h2_h1 = allel.moving_garud_h(ht, size=window_size,)\n",
    "                                     \n",
    "    print(\"compute window coordinates\")\n",
    "    x = allel.moving_statistic(pos, statistic=np.mean, size=window_size,)\n",
    "    return x, h12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec34887-b2a6-4d01-8622-998fd8396217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f1079a-31aa-4451-b47d-962122200587",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ca6671-3de2-4aad-ac0c-6727b4b4563f",
   "metadata": {},
   "source": [
    "### Run H12 calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b518f-812c-4f49-8c3d-74afcdf4f160",
   "metadata": {},
   "source": [
    "##### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022cecf-9b4a-4f05-9cfe-36f08cfec394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get optimal window sizes for Funestus cohorts\n",
    "chrom = 'X'\n",
    "for cohort_query in geographical_cohorts:\n",
    "\n",
    "    plot_h12_calibration(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                         cohort_set=\"geographic_cohort\", downsample=20, window_sizes=window_sizes, title=cohort_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f3c92-34d2-4a45-9e07-38c833c7ea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18725891-9d78-4a29-be96-89558876b7ec",
   "metadata": {},
   "source": [
    "##### 2RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a6b3f-9be2-40cc-9d10-ab5fd03a7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get optimal window sizes for Funestus cohorts\n",
    "chrom = '2RL'\n",
    "for cohort_query in geographic_cohorts:\n",
    "\n",
    "    plot_h12_calibration(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                         cohort_set=\"geographic_cohort\", downsample=20, window_sizes=window_sizes, title=cohort_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413116ab-1cd6-41f7-9216-6e2722d10a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17953960-fac5-4af9-91d6-54c49ba3831c",
   "metadata": {},
   "source": [
    "##### 3RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd92ca-0c6f-4827-b688-c1c3ae559b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get optimal window sizes for Funestus cohorts\n",
    "chrom = '3RL'\n",
    "for cohort_query in geographical_cohorts:\n",
    "\n",
    "    plot_h12_calibration(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                         cohort_set=\"geographic_cohort\", downsample=30, window_sizes=window_sizes, title=cohort_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920ef66-a965-465f-9568-e53b6fdc336e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d4760-aed2-46a9-88da-00b1464a8923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2937f910-5e27-4e57-8904-e4edc5f31d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dictionaries for the windows to use for computing the H12\n",
    "\n",
    "funestus_windows = {'2RL': {'Ghana_Northern-Region': 4000, 'Gabon_Haut-Ogooue': 4000, 'CAR_Ombella-M-Poko': 1000,\n",
    " 'Cameroon_Adamawa': 1000, 'Ghana_Ashanti-Region': 2000, 'Malawi_Southern-Region': 4000, 'Mozambique_Maputo': 4000,\n",
    " 'Uganda_Eastern-Region': 2000, 'Benin_Atlantique-Dept': 3000, 'DRC_Kinshasa': 4000, 'Nigeria_Ogun-State': 1000,\n",
    " 'Zambia_Eastern-Prov': 4000, 'Kenya_Nyanza-Prov': 1000, 'Kenya_Western-Prov': 2000, 'Tanzania_Morogoro-Region': 4000,\n",
    " 'DRC_Haut-Uele': 1000, 'Mozambique_Cabo-Delgado': 4000},\n",
    "                    \n",
    " '3RL': {'Ghana_Northern-Region': 4000, 'Gabon_Haut-Ogooue': 4000, 'CAR_Ombella-M-Poko': 2000, 'Cameroon_Adamawa': 2000,\n",
    " 'Ghana_Ashanti-Region': 2000, 'Malawi_Southern-Region': 4000, 'Mozambique_Maputo': 4000, 'Uganda_Eastern-Region': 2000,\n",
    " 'Benin_Atlantique-Dept': 4000, 'DRC_Kinshasa': 4000, 'Nigeria_Ogun-State': 4000, 'Zambia_Eastern-Prov': 3000,\n",
    " 'Kenya_Nyanza-Prov': 3000, 'Kenya_Western-Prov': 3000, 'Tanzania_Morogoro-Region': 4000, 'DRC_Haut-Uele': 1000,\n",
    " 'Mozambique_Cabo-Delgado': 4000},\n",
    "                    \n",
    " 'X': {'Ghana_Northern-Region': 4000, 'Gabon_Haut-Ogooue': 4000, 'CAR_Ombella-M-Poko': 1000, 'Cameroon_Adamawa': 1000,\n",
    " 'Ghana_Ashanti-Region': 1000, 'Malawi_Southern-Region': 4000, 'Mozambique_Maputo': 4000, 'Uganda_Eastern-Region': 1000,\n",
    " 'Benin_Atlantique-Dept': 3000, 'DRC_Kinshasa': 4000, 'Nigeria_Ogun-State': 1000, 'Zambia_Eastern-Prov': 4000,\n",
    " 'Kenya_Nyanza-Prov': 1000, 'Kenya_Western-Prov': 1000, 'Tanzania_Morogoro-Region': 4000, 'DRC_Haut-Uele': 1000,\n",
    " 'Mozambique_Cabo-Delgado': 4000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022eb92-764d-4d78-9b49-4841b6e3eba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c527b03-4028-4e4f-92ae-041c0464ba83",
   "metadata": {},
   "source": [
    "### Run H12 computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c62e62-2689-44a5-b0be-360165735425",
   "metadata": {},
   "source": [
    "##### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b484852-27e4-49b4-a245-2cfd8ad2969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = 'X'\n",
    "windowed_selection = {}\n",
    "for cohort_query in geographic_cohorts:\n",
    "\n",
    "    pos, h12 = h12_gwss(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                        cohort_set='geographic_cohort', window_size=funestus_windows[chrom][cohort_query])\n",
    "\n",
    "    windowed_selection[cohort_query] = h12, pos\n",
    "np.save(f'windowed_H12_geo_cohort_{chrom}.npy', windowed_selection,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8a62e-41a2-48ea-8645-dc2e21b6e7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28f69a2-97be-466e-98c3-f0614f323cf9",
   "metadata": {},
   "source": [
    "##### 2RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db5571-dd88-4417-908e-5b20a02d315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = '2RL'\n",
    "windowed_selection = {}\n",
    "for cohort_query in geographic_cohorts:\n",
    "\n",
    "    pos, h12 = h12_gwss(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                        cohort_set='geographic_cohort', window_size=funestus_windows[chrom][cohort_query])\n",
    "\n",
    "    windowed_selection[cohort_query] = h12, pos\n",
    "np.save(f'windowed_H12_geo_cohort_{chrom}.npy', windowed_selection,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d332309-d3d4-45fc-97fd-f8bfa14ff418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a568b57e-a090-4057-bdfa-fb70533c16ba",
   "metadata": {},
   "source": [
    "##### 3RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae2f97-0245-4ce6-ab92-cb4057b11d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = '3RL'\n",
    "windowed_selection = {}\n",
    "for cohort_query in geographic_cohorts:\n",
    "\n",
    "    pos, h12 = h12_gwss(chrom=chrom, analysis=analysis, cohort_query=cohort_query, sample_sets=tuple(sample_sets),\n",
    "                        cohort_set='geographic_cohort', window_size=funestus_windows[chrom][cohort_query])\n",
    "\n",
    "    windowed_selection[cohort_query] = h12, pos\n",
    "np.save(f'windowed_H12_geo_cohort_{chrom}.npy', windowed_selection,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10f566-e603-4294-abe0-8287d87e92d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7a783-bdca-40e4-8d19-760cbc657d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-mgenv-6.0.6",
   "language": "python",
   "name": "conda-env-global-global-mgenv-6.0.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
