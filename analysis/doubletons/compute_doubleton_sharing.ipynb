{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e901eb-e1ab-4fc8-9ac3-3148a8167805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import zarr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import allel\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False}) # Silence large chunk warnings\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "from dask_gateway import Gateway\n",
    "import functools\n",
    "import numcodecs\n",
    "from fsspec.implementations.zip import ZipFileSystem\n",
    "from collections.abc import Mapping\n",
    "import gcsfs\n",
    "import numba\n",
    "import psutil\n",
    "from humanize import naturalsize\n",
    "\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from pyprojroot import here\n",
    "from bokeh.plotting import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01f658-cc9d-4af9-ad17-e7256258ea9d",
   "metadata": {},
   "source": [
    "### Connect to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112507b-08d0-49a3-b46f-39b9d70e1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded9b92-0084-4456-a3e2-0326f4cc6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs.ls('vo_afun_release_master_us_central1')[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907e16c-1cdf-4d00-9bd9-e3b1af2f0a76",
   "metadata": {},
   "source": [
    "### Set up data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d00d95-8fb0-4d58-8f5d-20fa741d493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_root = Path('vo_afun_release_master_us_central1')\n",
    "vo_afun_staging = Path(production_root, 'v1.0')\n",
    "sampleset_staging_dir = Path(vo_afun_staging, 'snp_genotypes', 'all')\n",
    "\n",
    "#Decision tree or static filters\n",
    "genomic_positions_site_filter_dt_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/dt_20200416/funestus'\n",
    "genomic_positions_site_filter_sc_data_cloud_zarr_dir = 'vo_afun_release_master_us_central1/v1.0/site_filters/sc_20220908/funestus'\n",
    "\n",
    "repo_clone_path = here()\n",
    "release_config_path = repo_clone_path / 'analysis' / 'config.yml'\n",
    "\n",
    "with open(release_config_path) as fh:\n",
    "    config = yaml.load(fh, Loader=yaml.BaseLoader)\n",
    "    \n",
    "samplesets = config[\"sample_sets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e6748-a8fc-4b4a-b5d4-72b118c25b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../../metadata/supp1_tab2.csv\")\n",
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3e46c-3855-42e8-8155-95a02f51a28b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd35940-21f0-4fe9-ab8f-403d169fed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single array from field/chrom/sampleset\n",
    "# internal path for calldata is chrom/calldata/field\n",
    "# sampleset_calldata = sampleset_staging_dir / sset\n",
    "# sampleset is needed to load species spec.\n",
    "def load_single_field(zarr_path, internal_path, sset, exclude_males=False, samples=None):\n",
    "      \n",
    "    inz = zarr.group(is_gcloud(zarr_path), overwrite=False)\n",
    "    \n",
    "    oo = da.from_zarr(inz[internal_path])  \n",
    "    \n",
    "    if oo.ndim == 1:\n",
    "        oo = oo.reshape((1, -1))\n",
    "           \n",
    "    return oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2d87e7-e90f-4ecc-8975-f89686b5ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General function to concatenate data.\n",
    "## Selected chunk size may be more appropriate for some than others.\n",
    "def concatenate_along_axis(base_dir, internal_path, req_samplesets):\n",
    "    \n",
    "    # work out shape\n",
    "    data = [load_single_field(base_dir / ss, internal_path, ss) for ss in req_samplesets]\n",
    "    \n",
    "    return da.concatenate(data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af0f368-c3e5-4b4e-9481-f42730b63708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gcloud(path):\n",
    "    \n",
    "    try: \n",
    "        return gcs.get_mapper(path.as_posix())\n",
    "    except NameError as e:\n",
    "        return path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9ffc83-6894-4577-9ca3-a6ed36553fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter(chrom, filter_dir = genomic_positions_site_filter_sc_data_cloud_zarr_dir):\n",
    "    gcsmap = gcs.get_mapper(filter_dir)\n",
    "    genomic_positions_site_filter_data = zarr.Group(gcsmap, read_only=True)\n",
    "    filter_pass = da.from_zarr(\n",
    "            genomic_positions_site_filter_data[chrom]['variants/filter_pass'])\n",
    "    return filter_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30bca2e-58e4-4d13-bb07-38a08b23706a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_position(chrom):\n",
    "    store = gcs.get_mapper(\n",
    "        f'gs://vo_afun_release/v1.0/snp_genotypes/all/sites')\n",
    "    root = zarr.open(store, mode='r')\n",
    "    pos = root[chrom]['variants/POS'][:]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102d82b6-f549-43e6-ba9b-392c3204a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_genotypes_positions(chrom, samples_idx, samplesets, posl, posu, \\\n",
    "                                filter_dir = genomic_positions_site_filter_sc_data_cloud_zarr_dir):\n",
    "\n",
    "    # load the genotypes and positions\n",
    "    gt_d = concatenate_along_axis(sampleset_staging_dir, f\"{chrom}/calldata/GT\", samplesets)\n",
    "    gt = allel.GenotypeDaskArray(gt_d)\n",
    "    pos = load_position(chrom)\n",
    "    \n",
    "    if posu==-1:\n",
    "        posu = pos.max()+1\n",
    "        \n",
    "    if posl==-1:\n",
    "        posl = pos.min()\n",
    "    \n",
    "    #load the filter\n",
    "    loc_filt = load_filter(chrom, filter_dir)\n",
    "    \n",
    "    #filter by positions\n",
    "    pos_filt = (pos>=posl) & (pos<posu)\n",
    "    \n",
    "    #apply the filter to positions and genotypes\n",
    "    gt = gt.compress((loc_filt) & (pos_filt), axis=0)\n",
    "    pos = pos[(loc_filt) & (pos_filt)]\n",
    "    \n",
    "    #subset to desired samples \n",
    "    gt = da.take(gt, samples_idx, axis=1)\n",
    "    \n",
    "    \n",
    "    return gt, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5860bedf-20e3-48bb-971d-f862222118bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_in_genotypes_at_doubleton_positions(chrom, doubleton_pos, samples_idx, samplesets, \\\n",
    "                                filter_dir = genomic_positions_site_filter_sc_data_cloud_zarr_dir):\n",
    "\n",
    "    # load the genotypes and positions\n",
    "    gt_d = concatenate_along_axis(sampleset_staging_dir, f\"{chrom}/calldata/GT\", samplesets)\n",
    "    gt = allel.GenotypeDaskArray(gt_d)\n",
    "    pos = load_position(chrom)\n",
    "    \n",
    "    #filter by positions\n",
    "    pos_filt = np.isin(pos, doubleton_pos)\n",
    "    \n",
    "    #apply the filter to positions and genotypes\n",
    "    gt = gt.compress((pos_filt), axis=0)\n",
    "    \n",
    "    #subset to desired samples \n",
    "    gt = da.take(gt, samples_idx, axis=1)\n",
    "    \n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc3cfa8-7444-44e8-8835-5f24faab3978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_doubletons_rf(chrom, samples_idx, posl, posu, samplesets):\n",
    "    \n",
    "    gt, pos = read_in_genotypes_positions(chrom, samples_idx, samplesets, posl, posu)\n",
    "    \n",
    "    #count allles\n",
    "    ac = gt.count_alleles(max_allele=3)\n",
    "    \n",
    "    #identify at which sites there are doubletons\n",
    "    doubleton_sites = (ac==2).any(axis=1)\n",
    "    \n",
    "    gt_doub = gt.compress(doubleton_sites, axis=0)\n",
    "    \n",
    "    return gt_doub\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da38f0ed-5266-44b9-9bef-61452ebd39b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_doubletons_chrom(chrom, chromname, samples_idx, samplesets, posmin, posmax, reading_frame_size):\n",
    "    if posmax == -1:\n",
    "        posmax = load_position(chrom).max()\n",
    "        \n",
    "    rf_start = posmin\n",
    "    rf_end = min(rf_start + reading_frame_size, posmax)\n",
    "    gt_doub = identify_doubletons_rf(chrom, samples_idx, rf_start, rf_end, samplesets)\n",
    "    rf_start += reading_frame_size\n",
    "    while rf_end < posmax:\n",
    "        rf_end = min(rf_start + reading_frame_size, posmax)\n",
    "        gt_doub_rf = identify_doubletons_rf(chrom, samples_idx, rf_start, rf_end, \\\n",
    "                                    samplesets=samplesets)\n",
    "        gt_doub = gt_doub.concatenate([gt_doub_rf], axis=0)\n",
    "        rf_start += reading_frame_size\n",
    "        #print(f'identified {gt_doub.shape[0]} doubleton sites up to position {rf_end}')\n",
    "        \n",
    "    return  gt_doub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035e1b4e-f697-4382-ae3b-e8c2ffe3c388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_shared_doubletons(chrom, gt_doub, popdict, cohorts):\n",
    "    \n",
    "    #count alleles at doubleton sites\n",
    "    ac = gt_doub.count_alleles(max_allele=3)\n",
    "    print('finished counting alleles at doubleton sites')\n",
    "    \n",
    "    doubleton_counts = np.zeros((len(cohorts), len(cohorts)))\n",
    "    \n",
    "    #loop through alleles\n",
    "    for allele in np.arange(4):\n",
    "        doub = (ac[:,allele]==2)\n",
    "        #count alleles per cohort for sites with a doubleton at appropriate allele\n",
    "        gt_doub_allele = gt_doub.compress(doub, axis=0)\n",
    "        print(f'determined {gt_doub_allele.shape[0]} sites where allele {allele} is doubleton')\n",
    "        ac_subpop = gt_doub_allele.count_alleles_subpops(popdict, max_allele=3)\n",
    "        #count doubletons for each pair of cohorts\n",
    "        for r, cohort1 in enumerate(cohorts[:-1]):\n",
    "            #count doubletons shared within the cohort \n",
    "            doubleton_counts[r,r] += (ac_subpop[cohort1][:,allele]==2).sum().compute()\n",
    "            #count doubletons shared with every other cohort\n",
    "            for c, cohort2 in enumerate(cohorts[r+1:]):\n",
    "                doubleton_counts[r,r+1+c] += ((ac_subpop[cohort1][:,allele]==1) & \n",
    "                                         (ac_subpop[cohort2][:,allele]==1)).sum().compute()\n",
    "        r+=1\n",
    "        doubleton_counts[r,r] += (ac_subpop[cohorts[-1]][:,allele]==2).sum().compute()\n",
    "        print(f'allele {allele} done')\n",
    "        \n",
    "    return doubleton_counts\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb929c0-14fe-48fa-8f67-b8150f76d21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_shared_doubletons(chrom, chromname, cohorts, meta, outdir, posmin=-1, posmax=-1, samplesets=samplesets, \\\n",
    "                          reading_frame_size=15_000_000):\n",
    "    \n",
    "    samples_idx = meta.loc[meta.subset_3=='Y'].index\n",
    "    meta = meta.loc[samples_idx].reset_index(drop=True)\n",
    "    popdict = dict()\n",
    "    for cohort in cohorts:\n",
    "        popdict[cohort] = meta.loc[meta.geographic_cohort==cohort].index\n",
    "    \n",
    "    gt_doub = identify_doubletons_chrom(chrom, chromname, samples_idx, samplesets, \\\n",
    "                                              posmin, posmax, reading_frame_size) \n",
    "    print(f'identified {gt_doub.shape[0]} doubleton sites on {chromname}')\n",
    "    doubleton_counts = count_shared_doubletons(chrom, gt_doub, popdict, cohorts)\n",
    "    pd.DataFrame(doubleton_counts, index=cohorts, columns=cohorts).to_csv(f'{outdir}/doubletons_{chromname}.tsv', sep='\\t')\n",
    "    \n",
    "    return doubleton_counts\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3ec6d-d50a-4796-9907-3ccda477331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put meta in order as dask is stored\n",
    "sample_order = concatenate_along_axis(sampleset_staging_dir, \"samples\", samplesets).compute()\n",
    "sample_order = (sample_order[0]).astype(str)\n",
    "meta.set_index('VBS_sample_id', inplace=True)\n",
    "meta = meta.loc[sample_order]\n",
    "meta.reset_index(inplace=True)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc340e6-d6aa-420f-bb9a-95edd822b36e",
   "metadata": {},
   "source": [
    "### Set up dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd257b6f-e8a7-4ea0-ac86-875ab39750a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ClusterReport<name=dev.cc530628979a4bd7950435ac155f99f2, status=RUNNING>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a362ed1-654d-4cc2-90ad-992ccb18dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fb947ca702483fa7285991ccf291d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gateway = Gateway()\n",
    "conda_prefix = os.environ[\"CONDA_PREFIX\"]\n",
    "current_environment = 'global/'+conda_prefix.split('/')[5]\n",
    "cluster = gateway.new_cluster(\n",
    "    profile='standard', \n",
    "    conda_environment = current_environment,\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3fcf660-b618-45aa-860e-a99aa3a865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6311c415-bbd9-4b32-8ef0-87c11afa668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfc2a2b8-049f-4e92-a637-0227f44444bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohorts = ['Ghana_Northern-Region', 'Benin_Atlantique-Dept', 'Ghana_Ashanti-Region', \n",
    "                   'Nigeria_Ogun-State', 'Cameroon_Adamawa', 'CAR_Ombella-MPoko',\n",
    "                   'DRC_Haut-Uele', 'Uganda_Eastern-Region', 'Kenya_Western-Prov', \n",
    "                   'Kenya_Nyanza-Prov', 'Gabon_Haut-Ogooue', 'DRC_Kinshasa',\n",
    "                   'Tanzania_Morogoro-Region', 'Mozambique_Cabo-Delgado', \n",
    "                   'Zambia_Eastern-Prov', 'Malawi_Southern-Region', 'Mozambique_Maputo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09b91ecd-b0f8-427e-a02e-f69d15e66a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 1079777 doubleton sites on 2R2\n",
      "finished counting alleles at doubleton sites\n",
      "determined 1121 sites where allele 0 is doubleton\n",
      "allele 0 done\n",
      "determined 398065 sites where allele 1 is doubleton\n",
      "allele 1 done\n",
      "determined 424807 sites where allele 2 is doubleton\n",
      "allele 2 done\n",
      "determined 277136 sites where allele 3 is doubleton\n",
      "allele 3 done\n"
     ]
    }
   ],
   "source": [
    "df2r = compute_shared_doubletons('2RL', '2R2', cohorts, meta, 'doubletons/hic30/', posmin = 29_000_000, posmax=57_350_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13520dcd-1f0c-4b55-a2e2-0dd984199174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101129.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d714679-4db0-499e-a665-4fc49994442b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 1624993 doubleton sites on 2R1\n",
      "finished counting alleles at doubleton sites\n",
      "determined 1345 sites where allele 0 is doubleton\n",
      "allele 0 done\n",
      "determined 603563 sites where allele 1 is doubleton\n",
      "allele 1 done\n",
      "determined 642134 sites where allele 2 is doubleton\n",
      "allele 2 done\n",
      "determined 425578 sites where allele 3 is doubleton\n",
      "allele 3 done\n"
     ]
    }
   ],
   "source": [
    "df2r1 = compute_shared_doubletons('2RL', '2R1', cohorts, meta, 'doubletons/hic30/', posmax = 29_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e55f4fb-1705-45bb-8c02-bf417460d9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672620.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2r1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af1e13-cd22-4862-af1c-6d8e10615ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 2997380 doubleton sites on 2L\n",
      "finished counting alleles at doubleton sites\n",
      "determined 2321 sites where allele 0 is doubleton\n"
     ]
    }
   ],
   "source": [
    "df2l = compute_shared_doubletons('2RL', '2L', cohorts, meta, 'doubletons/hic30/', posmin = 57_350_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77617803-680e-43cc-bf44-5373d09400f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99774cbb-1070-4153-b43d-29c3c12e3627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 2067676 doubleton sites on 3R\n",
      "finished counting alleles at doubleton sites\n",
      "determined 1645 sites where allele 0 is doubleton\n",
      "allele 0 done\n",
      "determined 765002 sites where allele 1 is doubleton\n",
      "allele 1 done\n",
      "determined 814761 sites where allele 2 is doubleton\n",
      "allele 2 done\n",
      "determined 537484 sites where allele 3 is doubleton\n",
      "allele 3 done\n"
     ]
    }
   ],
   "source": [
    "df3r = compute_shared_doubletons('3RL', '3R', cohorts, meta, 'doubletons/hic30/', posmax = 44_700_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ac9a93-9cd3-4a6f-b5bd-66ec99165191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2118892.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66bdd60-9856-4f77-8dc0-335955b5bff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 1763527 doubleton sites on 3L\n",
      "finished counting alleles at doubleton sites\n",
      "determined 1654 sites where allele 0 is doubleton\n",
      "allele 0 done\n",
      "determined 653703 sites where allele 1 is doubleton\n",
      "allele 1 done\n",
      "determined 694537 sites where allele 2 is doubleton\n",
      "allele 2 done\n",
      "determined 459720 sites where allele 3 is doubleton\n",
      "allele 3 done\n"
     ]
    }
   ],
   "source": [
    "df3l = compute_shared_doubletons('3RL', '3L', cohorts, meta, 'doubletons/hic30/', posmin = 44_700_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0178955d-41bf-47d6-8e50-66ea58810c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1809614.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39cbbf5a-3125-4677-9fc3-09badb6f966a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 1034913 doubleton sites on X\n",
      "finished counting alleles at doubleton sites\n",
      "determined 539 sites where allele 0 is doubleton\n",
      "allele 0 done\n",
      "determined 388542 sites where allele 1 is doubleton\n",
      "allele 1 done\n",
      "determined 414850 sites where allele 2 is doubleton\n",
      "allele 2 done\n",
      "determined 267477 sites where allele 3 is doubleton\n",
      "allele 3 done\n"
     ]
    }
   ],
   "source": [
    "dfx = compute_shared_doubletons('X', 'X', cohorts, meta, 'doubletons/hic30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8968ce9b-d64f-49f8-9f7f-f4c938ff8409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071408.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afe081-0f3f-4df5-bfb4-b637c5cfd263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b5c595-45e0-499f-9b4d-696d80d1fd6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ebbf06-b2f7-4046-9372-3e1cae3050fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7c28a1-9e06-4ba0-b644-8f2ef96f7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for report in gateway.list_clusters():\n",
    "    gateway.connect(report.name).shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d242d8-2cdc-4d41-b081-2a27db589d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default *",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
